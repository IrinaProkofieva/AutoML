{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc4a5f440f814d36a516db384095c0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e85f708d976b465a9593d5e4154b0242",
              "IPY_MODEL_c8fa752716884a68bc4faff5f2d66bc2",
              "IPY_MODEL_4c8df702e9454b60990bf8f13bab914b"
            ],
            "layout": "IPY_MODEL_223dc378a1c94cbbb74f993d449a0037"
          }
        },
        "e85f708d976b465a9593d5e4154b0242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac178f87ef154a44b95aef885aa1baf1",
            "placeholder": "​",
            "style": "IPY_MODEL_a46342bc76984f28a5b6476decfa3fac",
            "value": "config.json: 100%"
          }
        },
        "c8fa752716884a68bc4faff5f2d66bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5afd47cf27846b89946eca5e1b28d00",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2682c401d57426f92136dba7c345cfa",
            "value": 625
          }
        },
        "4c8df702e9454b60990bf8f13bab914b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a6f4d9105b454eb7730041a641d351",
            "placeholder": "​",
            "style": "IPY_MODEL_57e8aa27034b412bbfe63f08a2a3f272",
            "value": " 625/625 [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "223dc378a1c94cbbb74f993d449a0037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac178f87ef154a44b95aef885aa1baf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46342bc76984f28a5b6476decfa3fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5afd47cf27846b89946eca5e1b28d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2682c401d57426f92136dba7c345cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68a6f4d9105b454eb7730041a641d351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e8aa27034b412bbfe63f08a2a3f272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb841467ec974c42939a8087b0cf415d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4bb9d57c937473baef23683d18549d1",
              "IPY_MODEL_74e740929fbd4ac98afaf6601d409626",
              "IPY_MODEL_eae2f8dc6cdc48fb9b0315a4330849e0"
            ],
            "layout": "IPY_MODEL_1a165d3b3f704095aee42f190a5ea32e"
          }
        },
        "c4bb9d57c937473baef23683d18549d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e86f52c2e143328b493498d16ebed7",
            "placeholder": "​",
            "style": "IPY_MODEL_58a395089fa3424b84473b38fa5a3ef8",
            "value": "model.safetensors: 100%"
          }
        },
        "74e740929fbd4ac98afaf6601d409626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d8b196a395493aaa18e211f8c3086a",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e155b0e860bf432895f619ff05cbd61c",
            "value": 714290682
          }
        },
        "eae2f8dc6cdc48fb9b0315a4330849e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26ad8022a5746a987847b200e8408c1",
            "placeholder": "​",
            "style": "IPY_MODEL_7b5ffcc06b014affb7a551c020883541",
            "value": " 714M/714M [00:04&lt;00:00, 173MB/s]"
          }
        },
        "1a165d3b3f704095aee42f190a5ea32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e86f52c2e143328b493498d16ebed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a395089fa3424b84473b38fa5a3ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67d8b196a395493aaa18e211f8c3086a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e155b0e860bf432895f619ff05cbd61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a26ad8022a5746a987847b200e8408c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5ffcc06b014affb7a551c020883541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c484812b5529406e8baea09c48330514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_859bc1203b004c83adf4abf5a5395285",
              "IPY_MODEL_30f4ce4e4fb44938b2c7e403f667c16b",
              "IPY_MODEL_ccd55ba1e287410e9ed57e797df5afe9"
            ],
            "layout": "IPY_MODEL_924b8e319bb54d92a1ec7df44df8a1be"
          }
        },
        "859bc1203b004c83adf4abf5a5395285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e01323e41d834fb3a3dbfe7b89d1b0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_d51f8ec8cd37456dabff0df268075288",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "30f4ce4e4fb44938b2c7e403f667c16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011ae70d661b4870acafb49da3b35c4f",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e80b6b7397a4ffaab10845936309e50",
            "value": 29
          }
        },
        "ccd55ba1e287410e9ed57e797df5afe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_335902acda7046f0a0d1244c26066f82",
            "placeholder": "​",
            "style": "IPY_MODEL_29aed23db37c4821be7bb1f8c126d4ee",
            "value": " 29.0/29.0 [00:00&lt;00:00, 562B/s]"
          }
        },
        "924b8e319bb54d92a1ec7df44df8a1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01323e41d834fb3a3dbfe7b89d1b0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51f8ec8cd37456dabff0df268075288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "011ae70d661b4870acafb49da3b35c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e80b6b7397a4ffaab10845936309e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "335902acda7046f0a0d1244c26066f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29aed23db37c4821be7bb1f8c126d4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0700025a9b04f3c96a1b7d18e476f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_453d2663db5b4aceb1d3cea5515b75bb",
              "IPY_MODEL_9a7a61664b334526bb75fb921b70fe51",
              "IPY_MODEL_582139d64ef24898be1bad66fdf4fb17"
            ],
            "layout": "IPY_MODEL_d5fd781a9c20487faab7a26e0706cc12"
          }
        },
        "453d2663db5b4aceb1d3cea5515b75bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de6830cbcbe4afbbb705d68f3511f41",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2715123aeb4df8a92c8527ccf9eefd",
            "value": "vocab.txt: 100%"
          }
        },
        "9a7a61664b334526bb75fb921b70fe51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de045e2c0274d3a8539b5499d4209c0",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_887c4b91e4da470b80dfb2abd47e305e",
            "value": 995526
          }
        },
        "582139d64ef24898be1bad66fdf4fb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb807e59fed54117a74d70043a66f967",
            "placeholder": "​",
            "style": "IPY_MODEL_09671f330d6f4328af4bee14bab09b06",
            "value": " 996k/996k [00:00&lt;00:00, 8.05MB/s]"
          }
        },
        "d5fd781a9c20487faab7a26e0706cc12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de6830cbcbe4afbbb705d68f3511f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2715123aeb4df8a92c8527ccf9eefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de045e2c0274d3a8539b5499d4209c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887c4b91e4da470b80dfb2abd47e305e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb807e59fed54117a74d70043a66f967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09671f330d6f4328af4bee14bab09b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b480b0fce61849368dee2427c1831309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df92c094cd249d1bcd7ab6841c07c54",
              "IPY_MODEL_84e9d2c143794670924d71796e025af9",
              "IPY_MODEL_32e5baf4118540298255fc4750ffbc8e"
            ],
            "layout": "IPY_MODEL_6ee304bb360247ac8a133cfe3a014680"
          }
        },
        "7df92c094cd249d1bcd7ab6841c07c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1429e6a3fafe46ef8a4d892a16bff873",
            "placeholder": "​",
            "style": "IPY_MODEL_0393bf690a864c4498eba989bb5978de",
            "value": "tokenizer.json: 100%"
          }
        },
        "84e9d2c143794670924d71796e025af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf32246cb94544eea586cfa171fe202e",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dfc8d4b726245d68d65748d71339a1e",
            "value": 1961828
          }
        },
        "32e5baf4118540298255fc4750ffbc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62927f97dff4eac855f71ebb222ff2a",
            "placeholder": "​",
            "style": "IPY_MODEL_0e405797df294dc69ed1094fc1f34869",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 25.1MB/s]"
          }
        },
        "6ee304bb360247ac8a133cfe3a014680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1429e6a3fafe46ef8a4d892a16bff873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0393bf690a864c4498eba989bb5978de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf32246cb94544eea586cfa171fe202e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfc8d4b726245d68d65748d71339a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b62927f97dff4eac855f71ebb222ff2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e405797df294dc69ed1094fc1f34869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206f2c1e370f495abf9894a591b1ae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfec27f9173b4c82a78c1f95f71abf50",
              "IPY_MODEL_6dc484d2813840fcb8b93fb25a958f24",
              "IPY_MODEL_09e1ca965376432dae267fbd742dadb4"
            ],
            "layout": "IPY_MODEL_ddba468618ed4ba89944501e67afc50b"
          }
        },
        "dfec27f9173b4c82a78c1f95f71abf50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afb9c56db7a4c28af53aae2b00b8b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8309b4557bc45dc88156bc5ee19242d",
            "value": "model.safetensors: 100%"
          }
        },
        "6dc484d2813840fcb8b93fb25a958f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9495c5dafa2c406abebcebc968ee62e7",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edcbabcce2d74af59dc750b73504ca91",
            "value": 498818054
          }
        },
        "09e1ca965376432dae267fbd742dadb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dddb4994b0ab4c44bd084150bebaac49",
            "placeholder": "​",
            "style": "IPY_MODEL_d1643b5559f248b493265274964bf9bd",
            "value": " 499M/499M [00:03&lt;00:00, 141MB/s]"
          }
        },
        "ddba468618ed4ba89944501e67afc50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afb9c56db7a4c28af53aae2b00b8b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8309b4557bc45dc88156bc5ee19242d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9495c5dafa2c406abebcebc968ee62e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcbabcce2d74af59dc750b73504ca91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dddb4994b0ab4c44bd084150bebaac49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1643b5559f248b493265274964bf9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrinaProkofieva/AutoML/blob/main/AutoML_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Установка зависимостей**"
      ],
      "metadata": {
        "id": "NCOw0Uae4Itr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1UyG3IQ1nAa"
      },
      "outputs": [],
      "source": [
        "!pip install -U lightautoml==0.3.8b1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "PaGxJDJ34Qzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "xvfrupqWV-La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "rG0Hq-hbptOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Импорты**"
      ],
      "metadata": {
        "id": "chY8Yb7k44mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8drnRr54foq",
        "outputId": "78a4631f-ffce-42f9-c6ef-5a32ff71e083"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "from lightautoml.addons.interpretation import LimeTextExplainer, L2XTextExplainer\n",
        "from lightautoml.report.report_deco import ReportDecoNLP"
      ],
      "metadata": {
        "id": "8yBLrr8T4kri"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "transformers.logging.set_verbosity(50)\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "import string\n",
        "import ast"
      ],
      "metadata": {
        "id": "laFq4wQi4mlq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "from datasets import load_metric, Dataset\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "MHpy6jITpi_2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "UygAYbPMOUZ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Достаем данные**"
      ],
      "metadata": {
        "id": "7J6n-OjyNl9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/toxic_comments/jigsaw-toxic-comment-train.csv')\n",
        "preprocessed_data = pd.read_csv('/content/drive/MyDrive/toxic_comments/preprocessed_train_data.csv')\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/toxic_comments/validation.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/toxic_comments/test.csv')\n",
        "test_labels = pd.read_csv('/content/drive/MyDrive/toxic_comments/test_labels.csv')"
      ],
      "metadata": {
        "id": "x-TggQ9ONsj7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/toxic_comments/sample_submission.csv')"
      ],
      "metadata": {
        "id": "5iWdyqC5yqgE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приведем данные к одному виду: добавим колонку с языком в тренировочный датасет, переименуем колонку с текстом в тестовой выборке."
      ],
      "metadata": {
        "id": "AZZi4rHrOWLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['lang'] = 'en'\n",
        "test_data = test_data.rename(columns={\"content\": \"comment_text\"})"
      ],
      "metadata": {
        "id": "yVDwT1dlOi8Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим новые признаки для дальнейшей очистки данных"
      ],
      "metadata": {
        "id": "tfYiagR8Oxxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enrich_data(data):\n",
        "  data['words_count'] = data['comment_text'].apply(lambda x: len(x.split()))\n",
        "  data['punctuation'] = data['comment_text'].apply(lambda x: len(list(filter(lambda c: c in string.punctuation, x))) / len(x))\n",
        "  data['uppercase'] = data['comment_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x))"
      ],
      "metadata": {
        "id": "SnIgtQQgODtg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enrich_data(train_data)\n",
        "enrich_data(preprocessed_data)"
      ],
      "metadata": {
        "id": "XJ2N5nbMOO0Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Очистим данные, удалим ненужные колонки"
      ],
      "metadata": {
        "id": "Tj41SZrVirJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для очистки датасета\n",
        "def clear_dataset(data):\n",
        "  return data[(data['punctuation'] < 0.5) & (data['words_count'] < 250)][['comment_text', 'toxic']]"
      ],
      "metadata": {
        "id": "VB9AgwyXiqVx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = clear_dataset(train_data)\n",
        "preprocessed_data = clear_dataset(preprocessed_data)"
      ],
      "metadata": {
        "id": "2NdO068iiu4n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_submissions(preds, filename):\n",
        "  submission['toxic'] = preds\n",
        "  submission.to_csv('/content/drive/MyDrive/toxic_comments/'+filename, index = False)"
      ],
      "metadata": {
        "id": "K4O_3dPPy-hY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LightAutoML подходы**"
      ],
      "metadata": {
        "id": "TfTDbPkgS0VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'target': 'toxic'\n",
        "}\n",
        "\n",
        "task = Task('binary')"
      ],
      "metadata": {
        "id": "XtiTRApoxRoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Подход 1 - Linear + LGBM + CatBoost --- Random LSTM**"
      ],
      "metadata": {
        "id": "cpEm7O4-3Sk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_3 = TabularNLPAutoML(\n",
        "    task = task,\n",
        "    timeout=3600,\n",
        "    cpu_limit=1,\n",
        "    gpu_ids='0',\n",
        "    reader_params={'n_jobs': 2, 'cv': 5, 'random_state': 42},\n",
        "    general_params={'use_algos': [['linear_l2', 'lgb', 'lgb_tuned', 'cb', 'cb_tuned']]},\n",
        "    tuning_params={'max_tuning_iter': 20, 'max_tuning_time': 30},\n",
        "    text_params = {'lang': 'multi'},\n",
        "    autonlp_params = {\n",
        "        'model_name': 'random_lstm',\n",
        "        'transformer_params': {\n",
        "            'model_params': {\n",
        "                'embed_size': 300, 'hidden_size': 256,\n",
        "                'pooling': 'mean', 'num_layers': 1\n",
        "                },\n",
        "            'dataset_params': {'max_length': 128, 'embed_size': 300}\n",
        "        }\n",
        "    },\n",
        "    memory_limit = 7\n",
        ")"
      ],
      "metadata": {
        "id": "4gO7RW-E0TSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оригинальный датасет (кросс-валидация)"
      ],
      "metadata": {
        "id": "hl60uK7WnG7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_pred_train_3 = automl_3.fit_predict(train_data.sample(frac=1), roles=roles, verbose = 10)\n",
        "val_pred_train_3 = automl_3.predict(val_data)"
      ],
      "metadata": {
        "id": "0FujmfBWm6I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c3d8d8-95e4-4f07-8105-23c611b10e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:09] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] - CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] - memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] \u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:10] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.84 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3599.84 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:51] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:51] Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:51] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:52] Linear model: C = 1e-05 score = 0.8704045044927755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8704045044927755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:52] Linear model: C = 5e-05 score = 0.8678348947516656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8678348947516656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:53] Linear model: C = 0.0001 score = 0.8683778405386054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8683778405386054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:53] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:53] Linear model: C = 1e-05 score = 0.8727534241601337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8727534241601337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:53] Linear model: C = 5e-05 score = 0.8694392734355509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8694392734355509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:54] Linear model: C = 0.0001 score = 0.8700624732805189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8700624732805189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:54] Linear model: C = 1e-05 score = 0.866442136387065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.866442136387065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:54] Linear model: C = 5e-05 score = 0.8639524216603471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8639524216603471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:55] Linear model: C = 0.0001 score = 0.864542520804159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.864542520804159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:55] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:55] Linear model: C = 1e-05 score = 0.8653813767644161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8653813767644161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:55] Linear model: C = 5e-05 score = 0.8623373458230459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8623373458230459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:55] Linear model: C = 0.0001 score = 0.8630554844004615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8630554844004615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] Linear model: C = 1e-05 score = 0.8696193420421507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8696193420421507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] Linear model: C = 5e-05 score = 0.8667711568607983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8667711568607983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] Linear model: C = 0.0001 score = 0.8673043747389222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8673043747389222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8677039354869397\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8677039354869397\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:56] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:01:57] Time left 3553.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3553.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:06:01] Feature concated__comment_text fitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text fitted\n",
            "100%|██████████| 209/209 [02:21<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:08:24] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:08:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:08:26] Training params: {'task': 'train', 'learning_rate': 0.04, 'num_leaves': 128, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 1, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 2000, 'early_stopping_rounds': 100, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.04, 'num_leaves': 128, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 1, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 2000, 'early_stopping_rounds': 100, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:08:27] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:08:53] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:32] [100]\tvalid's auc: 0.802825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.802825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:55] [200]\tvalid's auc: 0.806644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.806644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:13:32] [300]\tvalid's auc: 0.807703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.807703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:15:52] [400]\tvalid's auc: 0.80816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.80816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:09] Early stopping, best iteration is:\n",
            "[381]\tvalid's auc: 0.80842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[381]\tvalid's auc: 0.80842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:12] Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8084201976969193\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8084201976969193\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:12] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:12] Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.045, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.045, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:26] 0:\ttest: 0.6635741\tbest: 0.6635741 (0)\ttotal: 32.3ms\tremaining: 1m 4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6635741\tbest: 0.6635741 (0)\ttotal: 32.3ms\tremaining: 1m 4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:27] 100:\ttest: 0.7778230\tbest: 0.7778230 (100)\ttotal: 1.03s\tremaining: 19.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7778230\tbest: 0.7778230 (100)\ttotal: 1.03s\tremaining: 19.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:28] 200:\ttest: 0.7895100\tbest: 0.7895100 (200)\ttotal: 1.91s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7895100\tbest: 0.7895100 (200)\ttotal: 1.91s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:29] 300:\ttest: 0.7949590\tbest: 0.7949590 (300)\ttotal: 2.81s\tremaining: 15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7949590\tbest: 0.7949590 (300)\ttotal: 2.81s\tremaining: 15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:29] 400:\ttest: 0.7980616\tbest: 0.7980616 (400)\ttotal: 3.68s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7980616\tbest: 0.7980616 (400)\ttotal: 3.68s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:30] 500:\ttest: 0.7996872\tbest: 0.7996872 (500)\ttotal: 4.56s\tremaining: 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7996872\tbest: 0.7996872 (500)\ttotal: 4.56s\tremaining: 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:31] 600:\ttest: 0.8008854\tbest: 0.8008854 (600)\ttotal: 5.43s\tremaining: 12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8008854\tbest: 0.8008854 (600)\ttotal: 5.43s\tremaining: 12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:33] 700:\ttest: 0.8018058\tbest: 0.8018494 (699)\ttotal: 7.49s\tremaining: 13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8018058\tbest: 0.8018494 (699)\ttotal: 7.49s\tremaining: 13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:39] 800:\ttest: 0.8028427\tbest: 0.8028427 (800)\ttotal: 12.9s\tremaining: 19.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8028427\tbest: 0.8028427 (800)\ttotal: 12.9s\tremaining: 19.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:42] 900:\ttest: 0.8035896\tbest: 0.8036001 (896)\ttotal: 16.2s\tremaining: 19.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8035896\tbest: 0.8036001 (896)\ttotal: 16.2s\tremaining: 19.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:45] 1000:\ttest: 0.8042126\tbest: 0.8042130 (999)\ttotal: 19s\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8042126\tbest: 0.8042130 (999)\ttotal: 19s\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:47] 1100:\ttest: 0.8047768\tbest: 0.8047937 (1097)\ttotal: 21.4s\tremaining: 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8047768\tbest: 0.8047937 (1097)\ttotal: 21.4s\tremaining: 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:49] 1200:\ttest: 0.8052158\tbest: 0.8052206 (1193)\ttotal: 22.7s\tremaining: 15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8052158\tbest: 0.8052206 (1193)\ttotal: 22.7s\tremaining: 15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:52] 1300:\ttest: 0.8056404\tbest: 0.8056790 (1296)\ttotal: 26.4s\tremaining: 14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8056404\tbest: 0.8056790 (1296)\ttotal: 26.4s\tremaining: 14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:54] 1400:\ttest: 0.8060103\tbest: 0.8060386 (1398)\ttotal: 28.3s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8060103\tbest: 0.8060386 (1398)\ttotal: 28.3s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:55] 1500:\ttest: 0.8062866\tbest: 0.8063158 (1495)\ttotal: 29.2s\tremaining: 9.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8062866\tbest: 0.8063158 (1495)\ttotal: 29.2s\tremaining: 9.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:56] 1600:\ttest: 0.8067560\tbest: 0.8067628 (1597)\ttotal: 30.1s\tremaining: 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8067560\tbest: 0.8067628 (1597)\ttotal: 30.1s\tremaining: 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:57] 1700:\ttest: 0.8071964\tbest: 0.8072168 (1699)\ttotal: 31s\tremaining: 5.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8071964\tbest: 0.8072168 (1699)\ttotal: 31s\tremaining: 5.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:58] 1800:\ttest: 0.8071506\tbest: 0.8072670 (1784)\ttotal: 31.8s\tremaining: 3.52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8071506\tbest: 0.8072670 (1784)\ttotal: 31.8s\tremaining: 3.52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:17:59] 1900:\ttest: 0.8073860\tbest: 0.8074087 (1899)\ttotal: 32.7s\tremaining: 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8073860\tbest: 0.8074087 (1899)\ttotal: 32.7s\tremaining: 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:00] 1999:\ttest: 0.8075807\tbest: 0.8076726 (1963)\ttotal: 33.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8075807\tbest: 0.8076726 (1963)\ttotal: 33.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:00] bestTest = 0.8076726198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8076726198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:00] bestIteration = 1963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:00] Shrink model to first 1964 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1964 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:14] 0:\ttest: 0.6570507\tbest: 0.6570507 (0)\ttotal: 15.8ms\tremaining: 31.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6570507\tbest: 0.6570507 (0)\ttotal: 15.8ms\tremaining: 31.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:15] 100:\ttest: 0.7777787\tbest: 0.7777787 (100)\ttotal: 982ms\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777787\tbest: 0.7777787 (100)\ttotal: 982ms\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:16] 200:\ttest: 0.7891918\tbest: 0.7891918 (200)\ttotal: 1.86s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7891918\tbest: 0.7891918 (200)\ttotal: 1.86s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:16] 300:\ttest: 0.7939217\tbest: 0.7939217 (300)\ttotal: 2.73s\tremaining: 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7939217\tbest: 0.7939217 (300)\ttotal: 2.73s\tremaining: 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:17] 400:\ttest: 0.7969164\tbest: 0.7969164 (400)\ttotal: 3.57s\tremaining: 14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7969164\tbest: 0.7969164 (400)\ttotal: 3.57s\tremaining: 14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:18] 500:\ttest: 0.7987143\tbest: 0.7987143 (500)\ttotal: 4.41s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7987143\tbest: 0.7987143 (500)\ttotal: 4.41s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:19] 600:\ttest: 0.8002784\tbest: 0.8002784 (600)\ttotal: 5.4s\tremaining: 12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8002784\tbest: 0.8002784 (600)\ttotal: 5.4s\tremaining: 12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:23] 700:\ttest: 0.8015906\tbest: 0.8015906 (700)\ttotal: 8.91s\tremaining: 16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8015906\tbest: 0.8015906 (700)\ttotal: 8.91s\tremaining: 16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:25] 800:\ttest: 0.8022600\tbest: 0.8022600 (800)\ttotal: 11.3s\tremaining: 16.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8022600\tbest: 0.8022600 (800)\ttotal: 11.3s\tremaining: 16.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:26] 900:\ttest: 0.8029338\tbest: 0.8029427 (898)\ttotal: 12.2s\tremaining: 14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8029338\tbest: 0.8029427 (898)\ttotal: 12.2s\tremaining: 14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:27] 1000:\ttest: 0.8034612\tbest: 0.8034788 (992)\ttotal: 13.1s\tremaining: 13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8034612\tbest: 0.8034788 (992)\ttotal: 13.1s\tremaining: 13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:28] 1100:\ttest: 0.8039784\tbest: 0.8039784 (1100)\ttotal: 13.9s\tremaining: 11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8039784\tbest: 0.8039784 (1100)\ttotal: 13.9s\tremaining: 11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:29] 1200:\ttest: 0.8046769\tbest: 0.8046871 (1199)\ttotal: 14.7s\tremaining: 9.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8046769\tbest: 0.8046871 (1199)\ttotal: 14.7s\tremaining: 9.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:29] 1300:\ttest: 0.8049765\tbest: 0.8049846 (1299)\ttotal: 15.6s\tremaining: 8.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8049765\tbest: 0.8049846 (1299)\ttotal: 15.6s\tremaining: 8.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:30] 1400:\ttest: 0.8053596\tbest: 0.8053991 (1396)\ttotal: 16.5s\tremaining: 7.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8053596\tbest: 0.8053991 (1396)\ttotal: 16.5s\tremaining: 7.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:31] 1500:\ttest: 0.8058107\tbest: 0.8058107 (1500)\ttotal: 17.4s\tremaining: 5.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8058107\tbest: 0.8058107 (1500)\ttotal: 17.4s\tremaining: 5.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:32] 1600:\ttest: 0.8063341\tbest: 0.8063421 (1592)\ttotal: 18.2s\tremaining: 4.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8063341\tbest: 0.8063421 (1592)\ttotal: 18.2s\tremaining: 4.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:33] 1700:\ttest: 0.8068016\tbest: 0.8068260 (1691)\ttotal: 19.1s\tremaining: 3.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8068016\tbest: 0.8068260 (1691)\ttotal: 19.1s\tremaining: 3.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:34] 1800:\ttest: 0.8072287\tbest: 0.8072287 (1800)\ttotal: 20s\tremaining: 2.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8072287\tbest: 0.8072287 (1800)\ttotal: 20s\tremaining: 2.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:35] 1900:\ttest: 0.8074749\tbest: 0.8074749 (1900)\ttotal: 21.1s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8074749\tbest: 0.8074749 (1900)\ttotal: 21.1s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:39] 1999:\ttest: 0.8076340\tbest: 0.8076970 (1988)\ttotal: 25s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8076340\tbest: 0.8076970 (1988)\ttotal: 25s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:39] bestTest = 0.8076969683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8076969683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:39] bestIteration = 1988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:39] Shrink model to first 1989 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1989 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:40] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:55] 0:\ttest: 0.6597598\tbest: 0.6597598 (0)\ttotal: 47.6ms\tremaining: 1m 35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6597598\tbest: 0.6597598 (0)\ttotal: 47.6ms\tremaining: 1m 35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:57] 100:\ttest: 0.7750035\tbest: 0.7750035 (100)\ttotal: 2.15s\tremaining: 40.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7750035\tbest: 0.7750035 (100)\ttotal: 2.15s\tremaining: 40.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:58] 200:\ttest: 0.7850375\tbest: 0.7850375 (200)\ttotal: 3.01s\tremaining: 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7850375\tbest: 0.7850375 (200)\ttotal: 3.01s\tremaining: 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:18:59] 300:\ttest: 0.7898197\tbest: 0.7898197 (300)\ttotal: 3.89s\tremaining: 22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7898197\tbest: 0.7898197 (300)\ttotal: 3.89s\tremaining: 22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:00] 400:\ttest: 0.7924297\tbest: 0.7924297 (400)\ttotal: 4.73s\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7924297\tbest: 0.7924297 (400)\ttotal: 4.73s\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:01] 500:\ttest: 0.7942441\tbest: 0.7942441 (500)\ttotal: 5.61s\tremaining: 16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7942441\tbest: 0.7942441 (500)\ttotal: 5.61s\tremaining: 16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:01] 600:\ttest: 0.7956960\tbest: 0.7956960 (600)\ttotal: 6.48s\tremaining: 15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7956960\tbest: 0.7956960 (600)\ttotal: 6.48s\tremaining: 15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:02] 700:\ttest: 0.7966274\tbest: 0.7966274 (700)\ttotal: 7.33s\tremaining: 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7966274\tbest: 0.7966274 (700)\ttotal: 7.33s\tremaining: 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:03] 800:\ttest: 0.7973430\tbest: 0.7973467 (799)\ttotal: 8.19s\tremaining: 12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7973430\tbest: 0.7973467 (799)\ttotal: 8.19s\tremaining: 12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:04] 900:\ttest: 0.7983139\tbest: 0.7983139 (900)\ttotal: 9.06s\tremaining: 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7983139\tbest: 0.7983139 (900)\ttotal: 9.06s\tremaining: 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:05] 1000:\ttest: 0.7988713\tbest: 0.7988815 (998)\ttotal: 9.92s\tremaining: 9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7988713\tbest: 0.7988815 (998)\ttotal: 9.92s\tremaining: 9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:06] 1100:\ttest: 0.7994606\tbest: 0.7994975 (1098)\ttotal: 10.8s\tremaining: 8.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7994606\tbest: 0.7994975 (1098)\ttotal: 10.8s\tremaining: 8.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:07] 1200:\ttest: 0.8002083\tbest: 0.8002127 (1199)\ttotal: 12.1s\tremaining: 8.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8002083\tbest: 0.8002127 (1199)\ttotal: 12.1s\tremaining: 8.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:11] 1300:\ttest: 0.8008197\tbest: 0.8008197 (1300)\ttotal: 16s\tremaining: 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8008197\tbest: 0.8008197 (1300)\ttotal: 16s\tremaining: 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:13] 1400:\ttest: 0.8011881\tbest: 0.8012041 (1395)\ttotal: 17.6s\tremaining: 7.53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8011881\tbest: 0.8012041 (1395)\ttotal: 17.6s\tremaining: 7.53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:14] 1500:\ttest: 0.8014594\tbest: 0.8014615 (1491)\ttotal: 18.5s\tremaining: 6.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8014594\tbest: 0.8014615 (1491)\ttotal: 18.5s\tremaining: 6.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:14] 1600:\ttest: 0.8019322\tbest: 0.8019681 (1591)\ttotal: 19.3s\tremaining: 4.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8019322\tbest: 0.8019681 (1591)\ttotal: 19.3s\tremaining: 4.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:15] 1700:\ttest: 0.8021678\tbest: 0.8021678 (1700)\ttotal: 20.2s\tremaining: 3.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8021678\tbest: 0.8021678 (1700)\ttotal: 20.2s\tremaining: 3.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:16] 1800:\ttest: 0.8024145\tbest: 0.8024145 (1800)\ttotal: 21s\tremaining: 2.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8024145\tbest: 0.8024145 (1800)\ttotal: 21s\tremaining: 2.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:17] 1900:\ttest: 0.8026984\tbest: 0.8027489 (1896)\ttotal: 21.9s\tremaining: 1.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8026984\tbest: 0.8027489 (1896)\ttotal: 21.9s\tremaining: 1.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:18] 1999:\ttest: 0.8029358\tbest: 0.8029358 (1999)\ttotal: 22.8s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8029358\tbest: 0.8029358 (1999)\ttotal: 22.8s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:18] bestTest = 0.8029358089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8029358089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:18] bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:19] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:32] 0:\ttest: 0.6709516\tbest: 0.6709516 (0)\ttotal: 13.4ms\tremaining: 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6709516\tbest: 0.6709516 (0)\ttotal: 13.4ms\tremaining: 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] 100:\ttest: 0.7721754\tbest: 0.7721754 (100)\ttotal: 982ms\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7721754\tbest: 0.7721754 (100)\ttotal: 982ms\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:34] 200:\ttest: 0.7839792\tbest: 0.7839792 (200)\ttotal: 1.86s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7839792\tbest: 0.7839792 (200)\ttotal: 1.86s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:35] 300:\ttest: 0.7883057\tbest: 0.7883064 (299)\ttotal: 2.71s\tremaining: 15.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7883057\tbest: 0.7883064 (299)\ttotal: 2.71s\tremaining: 15.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:36] 400:\ttest: 0.7911812\tbest: 0.7911812 (400)\ttotal: 3.58s\tremaining: 14.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7911812\tbest: 0.7911812 (400)\ttotal: 3.58s\tremaining: 14.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:37] 500:\ttest: 0.7934899\tbest: 0.7934899 (500)\ttotal: 4.42s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7934899\tbest: 0.7934899 (500)\ttotal: 4.42s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:39] 600:\ttest: 0.7948035\tbest: 0.7948035 (600)\ttotal: 6.32s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7948035\tbest: 0.7948035 (600)\ttotal: 6.32s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:42] 700:\ttest: 0.7959839\tbest: 0.7960055 (698)\ttotal: 9.8s\tremaining: 18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7959839\tbest: 0.7960055 (698)\ttotal: 9.8s\tremaining: 18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:44] 800:\ttest: 0.7966356\tbest: 0.7966840 (792)\ttotal: 11.4s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7966356\tbest: 0.7966840 (792)\ttotal: 11.4s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:45] 900:\ttest: 0.7975565\tbest: 0.7975658 (899)\ttotal: 12.3s\tremaining: 15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7975565\tbest: 0.7975658 (899)\ttotal: 12.3s\tremaining: 15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:46] 1000:\ttest: 0.7981504\tbest: 0.7981928 (997)\ttotal: 13.2s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7981504\tbest: 0.7981928 (997)\ttotal: 13.2s\tremaining: 13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:47] 1100:\ttest: 0.7984862\tbest: 0.7985049 (1097)\ttotal: 14.1s\tremaining: 11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7984862\tbest: 0.7985049 (1097)\ttotal: 14.1s\tremaining: 11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:47] 1200:\ttest: 0.7991484\tbest: 0.7991484 (1200)\ttotal: 14.9s\tremaining: 9.92s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7991484\tbest: 0.7991484 (1200)\ttotal: 14.9s\tremaining: 9.92s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:48] 1300:\ttest: 0.7995805\tbest: 0.7995852 (1299)\ttotal: 15.8s\tremaining: 8.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7995805\tbest: 0.7995852 (1299)\ttotal: 15.8s\tremaining: 8.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:49] 1400:\ttest: 0.8000058\tbest: 0.8000247 (1396)\ttotal: 16.6s\tremaining: 7.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8000058\tbest: 0.8000247 (1396)\ttotal: 16.6s\tremaining: 7.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:50] 1500:\ttest: 0.8004230\tbest: 0.8004336 (1497)\ttotal: 17.5s\tremaining: 5.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8004230\tbest: 0.8004336 (1497)\ttotal: 17.5s\tremaining: 5.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:51] 1600:\ttest: 0.8008040\tbest: 0.8008046 (1599)\ttotal: 18.4s\tremaining: 4.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8008040\tbest: 0.8008046 (1599)\ttotal: 18.4s\tremaining: 4.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:52] 1700:\ttest: 0.8012457\tbest: 0.8012773 (1695)\ttotal: 19.2s\tremaining: 3.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8012457\tbest: 0.8012773 (1695)\ttotal: 19.2s\tremaining: 3.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:53] 1800:\ttest: 0.8016355\tbest: 0.8016355 (1800)\ttotal: 20.1s\tremaining: 2.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8016355\tbest: 0.8016355 (1800)\ttotal: 20.1s\tremaining: 2.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:55] 1900:\ttest: 0.8019745\tbest: 0.8019745 (1900)\ttotal: 22.2s\tremaining: 1.16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8019745\tbest: 0.8019745 (1900)\ttotal: 22.2s\tremaining: 1.16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:59] 1999:\ttest: 0.8022700\tbest: 0.8022781 (1998)\ttotal: 26.2s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8022700\tbest: 0.8022781 (1998)\ttotal: 26.2s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:59] bestTest = 0.8022780716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8022780716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:59] bestIteration = 1998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:59] Shrink model to first 1999 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1999 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:00] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:13] 0:\ttest: 0.6709093\tbest: 0.6709093 (0)\ttotal: 45.6ms\tremaining: 1m 31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6709093\tbest: 0.6709093 (0)\ttotal: 45.6ms\tremaining: 1m 31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:15] 100:\ttest: 0.7817797\tbest: 0.7817797 (100)\ttotal: 2.08s\tremaining: 39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7817797\tbest: 0.7817797 (100)\ttotal: 2.08s\tremaining: 39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:16] 200:\ttest: 0.7934358\tbest: 0.7934358 (200)\ttotal: 2.95s\tremaining: 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7934358\tbest: 0.7934358 (200)\ttotal: 2.95s\tremaining: 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:17] 300:\ttest: 0.7983841\tbest: 0.7983841 (300)\ttotal: 3.81s\tremaining: 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7983841\tbest: 0.7983841 (300)\ttotal: 3.81s\tremaining: 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:17] 400:\ttest: 0.8011733\tbest: 0.8011733 (400)\ttotal: 4.67s\tremaining: 18.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8011733\tbest: 0.8011733 (400)\ttotal: 4.67s\tremaining: 18.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:18] 500:\ttest: 0.8032201\tbest: 0.8032201 (500)\ttotal: 5.53s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8032201\tbest: 0.8032201 (500)\ttotal: 5.53s\tremaining: 16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:19] 600:\ttest: 0.8049414\tbest: 0.8049597 (599)\ttotal: 6.39s\tremaining: 14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8049414\tbest: 0.8049597 (599)\ttotal: 6.39s\tremaining: 14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:20] 700:\ttest: 0.8060865\tbest: 0.8060865 (700)\ttotal: 7.24s\tremaining: 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8060865\tbest: 0.8060865 (700)\ttotal: 7.24s\tremaining: 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:21] 800:\ttest: 0.8071800\tbest: 0.8071924 (798)\ttotal: 8.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8071800\tbest: 0.8071924 (798)\ttotal: 8.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:22] 900:\ttest: 0.8081897\tbest: 0.8081897 (900)\ttotal: 8.96s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8081897\tbest: 0.8081897 (900)\ttotal: 8.96s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:23] 1000:\ttest: 0.8088021\tbest: 0.8088080 (998)\ttotal: 9.82s\tremaining: 9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8088021\tbest: 0.8088080 (998)\ttotal: 9.82s\tremaining: 9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:23] 1100:\ttest: 0.8094235\tbest: 0.8094261 (1099)\ttotal: 10.7s\tremaining: 8.73s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8094235\tbest: 0.8094261 (1099)\ttotal: 10.7s\tremaining: 8.73s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:26] 1200:\ttest: 0.8099930\tbest: 0.8100143 (1198)\ttotal: 12.7s\tremaining: 8.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8099930\tbest: 0.8100143 (1198)\ttotal: 12.7s\tremaining: 8.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:30] 1300:\ttest: 0.8106789\tbest: 0.8106807 (1298)\ttotal: 16.7s\tremaining: 8.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8106789\tbest: 0.8106807 (1298)\ttotal: 16.7s\tremaining: 8.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:32] 1400:\ttest: 0.8111501\tbest: 0.8112161 (1394)\ttotal: 18.7s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8111501\tbest: 0.8112161 (1394)\ttotal: 18.7s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:36] 1500:\ttest: 0.8116549\tbest: 0.8116549 (1500)\ttotal: 22.9s\tremaining: 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8116549\tbest: 0.8116549 (1500)\ttotal: 22.9s\tremaining: 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:39] 1600:\ttest: 0.8122736\tbest: 0.8122736 (1600)\ttotal: 25.9s\tremaining: 6.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8122736\tbest: 0.8122736 (1600)\ttotal: 25.9s\tremaining: 6.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:40] 1700:\ttest: 0.8126135\tbest: 0.8126135 (1700)\ttotal: 26.8s\tremaining: 4.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8126135\tbest: 0.8126135 (1700)\ttotal: 26.8s\tremaining: 4.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:43] 1800:\ttest: 0.8129755\tbest: 0.8129755 (1800)\ttotal: 30.5s\tremaining: 3.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8129755\tbest: 0.8129755 (1800)\ttotal: 30.5s\tremaining: 3.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:46] 1900:\ttest: 0.8134024\tbest: 0.8134040 (1899)\ttotal: 32.9s\tremaining: 1.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8134024\tbest: 0.8134040 (1899)\ttotal: 32.9s\tremaining: 1.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] 1999:\ttest: 0.8137437\tbest: 0.8137437 (1999)\ttotal: 33.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8137437\tbest: 0.8137437 (1999)\ttotal: 33.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] bestTest = 0.8137437105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8137437105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8068328601782928\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8068328601782928\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:47] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightautoml.utils.timer:Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-7d825cb7-4fa9-499b-9ca9-ec28b6a3c64a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:04] 0:\ttest: 0.6402771\tbest: 0.6402771 (0)\ttotal: 11.5ms\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6402771\tbest: 0.6402771 (0)\ttotal: 11.5ms\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:05] 100:\ttest: 0.7722463\tbest: 0.7722463 (100)\ttotal: 852ms\tremaining: 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7722463\tbest: 0.7722463 (100)\ttotal: 852ms\tremaining: 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:06] 200:\ttest: 0.7863759\tbest: 0.7863759 (200)\ttotal: 1.6s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7863759\tbest: 0.7863759 (200)\ttotal: 1.6s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:07] 300:\ttest: 0.7918788\tbest: 0.7918815 (299)\ttotal: 2.35s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7918788\tbest: 0.7918815 (299)\ttotal: 2.35s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:07] 400:\ttest: 0.7953844\tbest: 0.7953844 (400)\ttotal: 3.09s\tremaining: 12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7953844\tbest: 0.7953844 (400)\ttotal: 3.09s\tremaining: 12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:08] 500:\ttest: 0.7975182\tbest: 0.7975182 (500)\ttotal: 3.82s\tremaining: 11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7975182\tbest: 0.7975182 (500)\ttotal: 3.82s\tremaining: 11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:09] 600:\ttest: 0.7991146\tbest: 0.7991146 (600)\ttotal: 4.57s\tremaining: 10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7991146\tbest: 0.7991146 (600)\ttotal: 4.57s\tremaining: 10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:10] 700:\ttest: 0.8003928\tbest: 0.8003928 (700)\ttotal: 5.27s\tremaining: 9.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8003928\tbest: 0.8003928 (700)\ttotal: 5.27s\tremaining: 9.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:10] 800:\ttest: 0.8014391\tbest: 0.8014565 (799)\ttotal: 6.01s\tremaining: 9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8014391\tbest: 0.8014565 (799)\ttotal: 6.01s\tremaining: 9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:13] 900:\ttest: 0.8023132\tbest: 0.8023132 (900)\ttotal: 8.96s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8023132\tbest: 0.8023132 (900)\ttotal: 8.96s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:16] 1000:\ttest: 0.8030883\tbest: 0.8030910 (999)\ttotal: 11.9s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8030883\tbest: 0.8030910 (999)\ttotal: 11.9s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:17] 1100:\ttest: 0.8036822\tbest: 0.8036905 (1095)\ttotal: 12.7s\tremaining: 10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8036822\tbest: 0.8036905 (1095)\ttotal: 12.7s\tremaining: 10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:18] 1200:\ttest: 0.8044061\tbest: 0.8044068 (1199)\ttotal: 13.4s\tremaining: 8.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8044061\tbest: 0.8044068 (1199)\ttotal: 13.4s\tremaining: 8.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:19] 1300:\ttest: 0.8048542\tbest: 0.8048542 (1300)\ttotal: 14.2s\tremaining: 7.61s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8048542\tbest: 0.8048542 (1300)\ttotal: 14.2s\tremaining: 7.61s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:19] 1400:\ttest: 0.8053155\tbest: 0.8053155 (1400)\ttotal: 14.9s\tremaining: 6.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8053155\tbest: 0.8053155 (1400)\ttotal: 14.9s\tremaining: 6.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:20] 1500:\ttest: 0.8056478\tbest: 0.8056478 (1500)\ttotal: 15.6s\tremaining: 5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8056478\tbest: 0.8056478 (1500)\ttotal: 15.6s\tremaining: 5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:21] 1600:\ttest: 0.8060236\tbest: 0.8060236 (1600)\ttotal: 16.4s\tremaining: 4.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8060236\tbest: 0.8060236 (1600)\ttotal: 16.4s\tremaining: 4.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:22] 1700:\ttest: 0.8063083\tbest: 0.8063158 (1698)\ttotal: 17.1s\tremaining: 3.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8063083\tbest: 0.8063158 (1698)\ttotal: 17.1s\tremaining: 3.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:22] 1800:\ttest: 0.8064771\tbest: 0.8065260 (1791)\ttotal: 17.9s\tremaining: 1.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8064771\tbest: 0.8065260 (1791)\ttotal: 17.9s\tremaining: 1.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:23] 1900:\ttest: 0.8068796\tbest: 0.8068796 (1900)\ttotal: 18.6s\tremaining: 968ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8068796\tbest: 0.8068796 (1900)\ttotal: 18.6s\tremaining: 968ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] 1999:\ttest: 0.8071213\tbest: 0.8071213 (1999)\ttotal: 19.3s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1999:\ttest: 0.8071213\tbest: 0.8071213 (1999)\ttotal: 19.3s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] bestTest = 0.8071213067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8071213067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.8071213620254781 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.8071213620254781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.8071213620254781 in 0:00:36.717644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.8071213620254781 in 0:00:36.717644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] The set of hyperparameters \u001b[1m{'max_depth': 4}\u001b[0m\n",
            " achieve 0.8071 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4}\u001b[0m\n",
            " achieve 0.8071 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:25] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:38] 0:\ttest: 0.6402771\tbest: 0.6402771 (0)\ttotal: 11.6ms\tremaining: 34.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6402771\tbest: 0.6402771 (0)\ttotal: 11.6ms\tremaining: 34.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:39] 100:\ttest: 0.7650828\tbest: 0.7650828 (100)\ttotal: 868ms\tremaining: 24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650828\tbest: 0.7650828 (100)\ttotal: 868ms\tremaining: 24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:40] 200:\ttest: 0.7784749\tbest: 0.7784749 (200)\ttotal: 1.63s\tremaining: 22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7784749\tbest: 0.7784749 (200)\ttotal: 1.63s\tremaining: 22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:41] 300:\ttest: 0.7859362\tbest: 0.7859362 (300)\ttotal: 2.34s\tremaining: 21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7859362\tbest: 0.7859362 (300)\ttotal: 2.34s\tremaining: 21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:42] 400:\ttest: 0.7905417\tbest: 0.7905417 (400)\ttotal: 3.77s\tremaining: 24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7905417\tbest: 0.7905417 (400)\ttotal: 3.77s\tremaining: 24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:46] 500:\ttest: 0.7936940\tbest: 0.7936940 (500)\ttotal: 7.19s\tremaining: 35.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7936940\tbest: 0.7936940 (500)\ttotal: 7.19s\tremaining: 35.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:47] 600:\ttest: 0.7956801\tbest: 0.7956801 (600)\ttotal: 9.06s\tremaining: 36.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7956801\tbest: 0.7956801 (600)\ttotal: 9.06s\tremaining: 36.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] 700:\ttest: 0.7971831\tbest: 0.7971831 (700)\ttotal: 9.79s\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7971831\tbest: 0.7971831 (700)\ttotal: 9.79s\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] 800:\ttest: 0.7984236\tbest: 0.7984236 (800)\ttotal: 10.5s\tremaining: 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7984236\tbest: 0.7984236 (800)\ttotal: 10.5s\tremaining: 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:50] 900:\ttest: 0.7992550\tbest: 0.7992550 (900)\ttotal: 11.3s\tremaining: 26.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7992550\tbest: 0.7992550 (900)\ttotal: 11.3s\tremaining: 26.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:50] 1000:\ttest: 0.8001103\tbest: 0.8001103 (1000)\ttotal: 12s\tremaining: 24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8001103\tbest: 0.8001103 (1000)\ttotal: 12s\tremaining: 24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:51] 1100:\ttest: 0.8007373\tbest: 0.8007373 (1100)\ttotal: 12.7s\tremaining: 21.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8007373\tbest: 0.8007373 (1100)\ttotal: 12.7s\tremaining: 21.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:52] 1200:\ttest: 0.8014271\tbest: 0.8014277 (1198)\ttotal: 13.5s\tremaining: 20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8014271\tbest: 0.8014277 (1198)\ttotal: 13.5s\tremaining: 20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:53] 1300:\ttest: 0.8020358\tbest: 0.8020594 (1299)\ttotal: 14.2s\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8020358\tbest: 0.8020594 (1299)\ttotal: 14.2s\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:53] 1400:\ttest: 0.8024217\tbest: 0.8024217 (1400)\ttotal: 15s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8024217\tbest: 0.8024217 (1400)\ttotal: 15s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:54] 1500:\ttest: 0.8027660\tbest: 0.8027697 (1498)\ttotal: 15.7s\tremaining: 15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8027660\tbest: 0.8027697 (1498)\ttotal: 15.7s\tremaining: 15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:55] 1600:\ttest: 0.8032955\tbest: 0.8032955 (1600)\ttotal: 16.4s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8032955\tbest: 0.8032955 (1600)\ttotal: 16.4s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:56] 1700:\ttest: 0.8037204\tbest: 0.8037204 (1700)\ttotal: 17.2s\tremaining: 13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8037204\tbest: 0.8037204 (1700)\ttotal: 17.2s\tremaining: 13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:57] 1800:\ttest: 0.8040413\tbest: 0.8040646 (1793)\ttotal: 18s\tremaining: 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8040413\tbest: 0.8040646 (1793)\ttotal: 18s\tremaining: 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:59] 1900:\ttest: 0.8044667\tbest: 0.8044667 (1900)\ttotal: 20.7s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8044667\tbest: 0.8044667 (1900)\ttotal: 20.7s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:03] 2000:\ttest: 0.8047259\tbest: 0.8047259 (2000)\ttotal: 24s\tremaining: 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.8047259\tbest: 0.8047259 (2000)\ttotal: 24s\tremaining: 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:03] 2100:\ttest: 0.8049927\tbest: 0.8050043 (2099)\ttotal: 24.9s\tremaining: 10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.8049927\tbest: 0.8050043 (2099)\ttotal: 24.9s\tremaining: 10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:04] 2200:\ttest: 0.8053130\tbest: 0.8053130 (2200)\ttotal: 25.6s\tremaining: 9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.8053130\tbest: 0.8053130 (2200)\ttotal: 25.6s\tremaining: 9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:05] 2300:\ttest: 0.8056696\tbest: 0.8056698 (2299)\ttotal: 26.4s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.8056696\tbest: 0.8056698 (2299)\ttotal: 26.4s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:06] 2400:\ttest: 0.8059179\tbest: 0.8059272 (2395)\ttotal: 27.1s\tremaining: 6.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.8059179\tbest: 0.8059272 (2395)\ttotal: 27.1s\tremaining: 6.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:06] 2500:\ttest: 0.8062085\tbest: 0.8062085 (2500)\ttotal: 27.9s\tremaining: 5.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.8062085\tbest: 0.8062085 (2500)\ttotal: 27.9s\tremaining: 5.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:07] 2600:\ttest: 0.8065178\tbest: 0.8065178 (2600)\ttotal: 28.6s\tremaining: 4.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.8065178\tbest: 0.8065178 (2600)\ttotal: 28.6s\tremaining: 4.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:08] 2700:\ttest: 0.8066803\tbest: 0.8066813 (2699)\ttotal: 29.4s\tremaining: 3.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.8066803\tbest: 0.8066813 (2699)\ttotal: 29.4s\tremaining: 3.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:09] 2800:\ttest: 0.8069215\tbest: 0.8069215 (2800)\ttotal: 30.1s\tremaining: 2.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\ttest: 0.8069215\tbest: 0.8069215 (2800)\ttotal: 30.1s\tremaining: 2.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:09] 2900:\ttest: 0.8071537\tbest: 0.8071537 (2900)\ttotal: 30.9s\tremaining: 1.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\ttest: 0.8071537\tbest: 0.8071537 (2900)\ttotal: 30.9s\tremaining: 1.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:10] 2999:\ttest: 0.8073740\tbest: 0.8073740 (2999)\ttotal: 31.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\ttest: 0.8073740\tbest: 0.8073740 (2999)\ttotal: 31.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:10] bestTest = 0.8073740005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8073740005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:10] bestIteration = 2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:11] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:24] 0:\ttest: 0.6364423\tbest: 0.6364423 (0)\ttotal: 11.4ms\tremaining: 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6364423\tbest: 0.6364423 (0)\ttotal: 11.4ms\tremaining: 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:25] 100:\ttest: 0.7650905\tbest: 0.7650905 (100)\ttotal: 877ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650905\tbest: 0.7650905 (100)\ttotal: 877ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:26] 200:\ttest: 0.7771942\tbest: 0.7771942 (200)\ttotal: 1.65s\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7771942\tbest: 0.7771942 (200)\ttotal: 1.65s\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:27] 300:\ttest: 0.7852043\tbest: 0.7852043 (300)\ttotal: 2.44s\tremaining: 21.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7852043\tbest: 0.7852043 (300)\ttotal: 2.44s\tremaining: 21.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:27] 400:\ttest: 0.7893680\tbest: 0.7893680 (400)\ttotal: 3.15s\tremaining: 20.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7893680\tbest: 0.7893680 (400)\ttotal: 3.15s\tremaining: 20.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:30] 500:\ttest: 0.7923726\tbest: 0.7923726 (500)\ttotal: 5.27s\tremaining: 26.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7923726\tbest: 0.7923726 (500)\ttotal: 5.27s\tremaining: 26.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:33] 600:\ttest: 0.7943605\tbest: 0.7943605 (600)\ttotal: 8.91s\tremaining: 35.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7943605\tbest: 0.7943605 (600)\ttotal: 8.91s\tremaining: 35.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:34] 700:\ttest: 0.7958440\tbest: 0.7958440 (700)\ttotal: 9.8s\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7958440\tbest: 0.7958440 (700)\ttotal: 9.8s\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:35] 800:\ttest: 0.7970134\tbest: 0.7970134 (800)\ttotal: 10.6s\tremaining: 29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7970134\tbest: 0.7970134 (800)\ttotal: 10.6s\tremaining: 29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:36] 900:\ttest: 0.7980572\tbest: 0.7980572 (900)\ttotal: 11.3s\tremaining: 26.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7980572\tbest: 0.7980572 (900)\ttotal: 11.3s\tremaining: 26.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:36] 1000:\ttest: 0.7988226\tbest: 0.7988226 (1000)\ttotal: 12s\tremaining: 24.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7988226\tbest: 0.7988226 (1000)\ttotal: 12s\tremaining: 24.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:37] 1100:\ttest: 0.7995744\tbest: 0.7995744 (1100)\ttotal: 12.8s\tremaining: 22.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7995744\tbest: 0.7995744 (1100)\ttotal: 12.8s\tremaining: 22.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:38] 1200:\ttest: 0.8001251\tbest: 0.8001251 (1200)\ttotal: 13.5s\tremaining: 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8001251\tbest: 0.8001251 (1200)\ttotal: 13.5s\tremaining: 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:39] 1300:\ttest: 0.8007648\tbest: 0.8007669 (1299)\ttotal: 14.2s\tremaining: 18.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8007648\tbest: 0.8007669 (1299)\ttotal: 14.2s\tremaining: 18.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:39] 1400:\ttest: 0.8012806\tbest: 0.8012806 (1400)\ttotal: 15s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8012806\tbest: 0.8012806 (1400)\ttotal: 15s\tremaining: 17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:40] 1500:\ttest: 0.8018723\tbest: 0.8018723 (1500)\ttotal: 15.7s\tremaining: 15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8018723\tbest: 0.8018723 (1500)\ttotal: 15.7s\tremaining: 15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:41] 1600:\ttest: 0.8023428\tbest: 0.8023428 (1600)\ttotal: 16.5s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8023428\tbest: 0.8023428 (1600)\ttotal: 16.5s\tremaining: 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:42] 1700:\ttest: 0.8028742\tbest: 0.8028742 (1700)\ttotal: 17.2s\tremaining: 13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8028742\tbest: 0.8028742 (1700)\ttotal: 17.2s\tremaining: 13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:42] 1800:\ttest: 0.8032946\tbest: 0.8032946 (1800)\ttotal: 18s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8032946\tbest: 0.8032946 (1800)\ttotal: 18s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:43] 1900:\ttest: 0.8036705\tbest: 0.8036759 (1898)\ttotal: 18.7s\tremaining: 10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8036705\tbest: 0.8036759 (1898)\ttotal: 18.7s\tremaining: 10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:46] 2000:\ttest: 0.8040644\tbest: 0.8040644 (2000)\ttotal: 21.5s\tremaining: 10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.8040644\tbest: 0.8040644 (2000)\ttotal: 21.5s\tremaining: 10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:49] 2100:\ttest: 0.8044145\tbest: 0.8044337 (2099)\ttotal: 24.6s\tremaining: 10.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.8044145\tbest: 0.8044337 (2099)\ttotal: 24.6s\tremaining: 10.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:50] 2200:\ttest: 0.8047143\tbest: 0.8047143 (2200)\ttotal: 25.4s\tremaining: 9.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.8047143\tbest: 0.8047143 (2200)\ttotal: 25.4s\tremaining: 9.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:51] 2300:\ttest: 0.8051569\tbest: 0.8051569 (2300)\ttotal: 26.1s\tremaining: 7.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.8051569\tbest: 0.8051569 (2300)\ttotal: 26.1s\tremaining: 7.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:51] 2400:\ttest: 0.8054533\tbest: 0.8054533 (2400)\ttotal: 26.8s\tremaining: 6.69s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.8054533\tbest: 0.8054533 (2400)\ttotal: 26.8s\tremaining: 6.69s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:52] 2500:\ttest: 0.8057473\tbest: 0.8057473 (2500)\ttotal: 27.6s\tremaining: 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.8057473\tbest: 0.8057473 (2500)\ttotal: 27.6s\tremaining: 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:53] 2600:\ttest: 0.8060734\tbest: 0.8060734 (2600)\ttotal: 28.3s\tremaining: 4.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.8060734\tbest: 0.8060734 (2600)\ttotal: 28.3s\tremaining: 4.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:54] 2700:\ttest: 0.8063362\tbest: 0.8063362 (2700)\ttotal: 29s\tremaining: 3.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.8063362\tbest: 0.8063362 (2700)\ttotal: 29s\tremaining: 3.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:54] 2800:\ttest: 0.8066140\tbest: 0.8066236 (2796)\ttotal: 29.8s\tremaining: 2.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\ttest: 0.8066140\tbest: 0.8066236 (2796)\ttotal: 29.8s\tremaining: 2.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:55] 2900:\ttest: 0.8069240\tbest: 0.8069240 (2900)\ttotal: 30.5s\tremaining: 1.04s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\ttest: 0.8069240\tbest: 0.8069240 (2900)\ttotal: 30.5s\tremaining: 1.04s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:56] 2999:\ttest: 0.8071884\tbest: 0.8071911 (2997)\ttotal: 31.2s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\ttest: 0.8071884\tbest: 0.8071911 (2997)\ttotal: 31.2s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:56] bestTest = 0.8071911037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8071911037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:56] bestIteration = 2997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:56] Shrink model to first 2998 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2998 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:57] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:10] 0:\ttest: 0.6501637\tbest: 0.6501637 (0)\ttotal: 12.3ms\tremaining: 36.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6501637\tbest: 0.6501637 (0)\ttotal: 12.3ms\tremaining: 36.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:11] 100:\ttest: 0.7628200\tbest: 0.7628200 (100)\ttotal: 877ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7628200\tbest: 0.7628200 (100)\ttotal: 877ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:12] 200:\ttest: 0.7741894\tbest: 0.7741894 (200)\ttotal: 1.64s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7741894\tbest: 0.7741894 (200)\ttotal: 1.64s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:12] 300:\ttest: 0.7810861\tbest: 0.7810861 (300)\ttotal: 2.39s\tremaining: 21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7810861\tbest: 0.7810861 (300)\ttotal: 2.39s\tremaining: 21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:13] 400:\ttest: 0.7849045\tbest: 0.7849045 (400)\ttotal: 3.13s\tremaining: 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7849045\tbest: 0.7849045 (400)\ttotal: 3.13s\tremaining: 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:14] 500:\ttest: 0.7875531\tbest: 0.7875531 (500)\ttotal: 3.88s\tremaining: 19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7875531\tbest: 0.7875531 (500)\ttotal: 3.88s\tremaining: 19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:16] 600:\ttest: 0.7894161\tbest: 0.7894161 (600)\ttotal: 6.07s\tremaining: 24.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7894161\tbest: 0.7894161 (600)\ttotal: 6.07s\tremaining: 24.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:20] 700:\ttest: 0.7906684\tbest: 0.7906834 (698)\ttotal: 9.74s\tremaining: 32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7906684\tbest: 0.7906834 (698)\ttotal: 9.74s\tremaining: 32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:21] 800:\ttest: 0.7919897\tbest: 0.7919897 (800)\ttotal: 10.7s\tremaining: 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7919897\tbest: 0.7919897 (800)\ttotal: 10.7s\tremaining: 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:21] 900:\ttest: 0.7928963\tbest: 0.7928963 (900)\ttotal: 11.4s\tremaining: 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7928963\tbest: 0.7928963 (900)\ttotal: 11.4s\tremaining: 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:22] 1000:\ttest: 0.7935762\tbest: 0.7935801 (997)\ttotal: 12.2s\tremaining: 24.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7935762\tbest: 0.7935801 (997)\ttotal: 12.2s\tremaining: 24.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:23] 1100:\ttest: 0.7942719\tbest: 0.7942719 (1100)\ttotal: 12.9s\tremaining: 22.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7942719\tbest: 0.7942719 (1100)\ttotal: 12.9s\tremaining: 22.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:24] 1200:\ttest: 0.7948526\tbest: 0.7948685 (1193)\ttotal: 13.6s\tremaining: 20.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7948526\tbest: 0.7948685 (1193)\ttotal: 13.6s\tremaining: 20.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:24] 1300:\ttest: 0.7954189\tbest: 0.7954189 (1300)\ttotal: 14.4s\tremaining: 18.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7954189\tbest: 0.7954189 (1300)\ttotal: 14.4s\tremaining: 18.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:25] 1400:\ttest: 0.7958117\tbest: 0.7958117 (1400)\ttotal: 15.1s\tremaining: 17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7958117\tbest: 0.7958117 (1400)\ttotal: 15.1s\tremaining: 17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:26] 1500:\ttest: 0.7963140\tbest: 0.7963203 (1499)\ttotal: 15.8s\tremaining: 15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7963140\tbest: 0.7963203 (1499)\ttotal: 15.8s\tremaining: 15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:27] 1600:\ttest: 0.7967892\tbest: 0.7967892 (1600)\ttotal: 16.6s\tremaining: 14.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7967892\tbest: 0.7967892 (1600)\ttotal: 16.6s\tremaining: 14.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:28] 1700:\ttest: 0.7971269\tbest: 0.7971303 (1692)\ttotal: 17.4s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7971269\tbest: 0.7971303 (1692)\ttotal: 17.4s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:28] 1800:\ttest: 0.7974940\tbest: 0.7974940 (1800)\ttotal: 18.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7974940\tbest: 0.7974940 (1800)\ttotal: 18.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:29] 1900:\ttest: 0.7977717\tbest: 0.7977759 (1899)\ttotal: 18.9s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7977717\tbest: 0.7977759 (1899)\ttotal: 18.9s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:30] 2000:\ttest: 0.7980715\tbest: 0.7980715 (2000)\ttotal: 19.6s\tremaining: 9.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.7980715\tbest: 0.7980715 (2000)\ttotal: 19.6s\tremaining: 9.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:33] 2100:\ttest: 0.7984142\tbest: 0.7984142 (2100)\ttotal: 22.4s\tremaining: 9.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.7984142\tbest: 0.7984142 (2100)\ttotal: 22.4s\tremaining: 9.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:36] 2200:\ttest: 0.7987232\tbest: 0.7987232 (2200)\ttotal: 25.6s\tremaining: 9.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.7987232\tbest: 0.7987232 (2200)\ttotal: 25.6s\tremaining: 9.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:37] 2300:\ttest: 0.7990010\tbest: 0.7990010 (2300)\ttotal: 26.4s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.7990010\tbest: 0.7990010 (2300)\ttotal: 26.4s\tremaining: 8.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:37] 2400:\ttest: 0.7992419\tbest: 0.7992419 (2400)\ttotal: 27.1s\tremaining: 6.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.7992419\tbest: 0.7992419 (2400)\ttotal: 27.1s\tremaining: 6.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:38] 2500:\ttest: 0.7995261\tbest: 0.7995261 (2500)\ttotal: 27.9s\tremaining: 5.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.7995261\tbest: 0.7995261 (2500)\ttotal: 27.9s\tremaining: 5.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:39] 2600:\ttest: 0.7998099\tbest: 0.7998142 (2598)\ttotal: 28.6s\tremaining: 4.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.7998099\tbest: 0.7998142 (2598)\ttotal: 28.6s\tremaining: 4.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:40] 2700:\ttest: 0.8001105\tbest: 0.8001163 (2697)\ttotal: 29.4s\tremaining: 3.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.8001105\tbest: 0.8001163 (2697)\ttotal: 29.4s\tremaining: 3.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:40] 2800:\ttest: 0.8003560\tbest: 0.8003597 (2794)\ttotal: 30.1s\tremaining: 2.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\ttest: 0.8003560\tbest: 0.8003597 (2794)\ttotal: 30.1s\tremaining: 2.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:41] 2900:\ttest: 0.8005618\tbest: 0.8005698 (2895)\ttotal: 30.9s\tremaining: 1.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\ttest: 0.8005618\tbest: 0.8005698 (2895)\ttotal: 30.9s\tremaining: 1.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:42] 2999:\ttest: 0.8007282\tbest: 0.8007325 (2996)\ttotal: 31.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\ttest: 0.8007282\tbest: 0.8007325 (2996)\ttotal: 31.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:42] bestTest = 0.8007324934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8007324934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:42] bestIteration = 2996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:42] Shrink model to first 2997 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2997 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:43] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:57] 0:\ttest: 0.6558930\tbest: 0.6558930 (0)\ttotal: 11.5ms\tremaining: 34.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6558930\tbest: 0.6558930 (0)\ttotal: 11.5ms\tremaining: 34.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:58] 100:\ttest: 0.7600963\tbest: 0.7600963 (100)\ttotal: 878ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7600963\tbest: 0.7600963 (100)\ttotal: 878ms\tremaining: 25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:58] 200:\ttest: 0.7736662\tbest: 0.7736662 (200)\ttotal: 1.66s\tremaining: 23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7736662\tbest: 0.7736662 (200)\ttotal: 1.66s\tremaining: 23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:23:59] 300:\ttest: 0.7809636\tbest: 0.7809674 (299)\ttotal: 2.46s\tremaining: 22.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7809636\tbest: 0.7809674 (299)\ttotal: 2.46s\tremaining: 22.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:00] 400:\ttest: 0.7850918\tbest: 0.7850918 (400)\ttotal: 3.19s\tremaining: 20.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7850918\tbest: 0.7850918 (400)\ttotal: 3.19s\tremaining: 20.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:01] 500:\ttest: 0.7877498\tbest: 0.7877498 (500)\ttotal: 3.93s\tremaining: 19.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7877498\tbest: 0.7877498 (500)\ttotal: 3.93s\tremaining: 19.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:03] 600:\ttest: 0.7898994\tbest: 0.7898994 (600)\ttotal: 5.79s\tremaining: 23.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7898994\tbest: 0.7898994 (600)\ttotal: 5.79s\tremaining: 23.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:06] 700:\ttest: 0.7912280\tbest: 0.7912280 (700)\ttotal: 9.53s\tremaining: 31.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7912280\tbest: 0.7912280 (700)\ttotal: 9.53s\tremaining: 31.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:08] 800:\ttest: 0.7922827\tbest: 0.7922827 (800)\ttotal: 10.8s\tremaining: 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7922827\tbest: 0.7922827 (800)\ttotal: 10.8s\tremaining: 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:08] 900:\ttest: 0.7933003\tbest: 0.7933005 (899)\ttotal: 11.5s\tremaining: 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7933003\tbest: 0.7933005 (899)\ttotal: 11.5s\tremaining: 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:09] 1000:\ttest: 0.7940781\tbest: 0.7940781 (1000)\ttotal: 12.2s\tremaining: 24.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7940781\tbest: 0.7940781 (1000)\ttotal: 12.2s\tremaining: 24.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:10] 1100:\ttest: 0.7945997\tbest: 0.7946051 (1099)\ttotal: 13s\tremaining: 22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7945997\tbest: 0.7946051 (1099)\ttotal: 13s\tremaining: 22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:11] 1200:\ttest: 0.7952006\tbest: 0.7952006 (1200)\ttotal: 13.7s\tremaining: 20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7952006\tbest: 0.7952006 (1200)\ttotal: 13.7s\tremaining: 20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:11] 1300:\ttest: 0.7957141\tbest: 0.7957155 (1298)\ttotal: 14.4s\tremaining: 18.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7957141\tbest: 0.7957155 (1298)\ttotal: 14.4s\tremaining: 18.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:12] 1400:\ttest: 0.7962596\tbest: 0.7962596 (1400)\ttotal: 15.2s\tremaining: 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7962596\tbest: 0.7962596 (1400)\ttotal: 15.2s\tremaining: 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:13] 1500:\ttest: 0.7967395\tbest: 0.7967395 (1500)\ttotal: 15.9s\tremaining: 15.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7967395\tbest: 0.7967395 (1500)\ttotal: 15.9s\tremaining: 15.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:13] 1600:\ttest: 0.7971438\tbest: 0.7971443 (1599)\ttotal: 16.6s\tremaining: 14.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7971438\tbest: 0.7971443 (1599)\ttotal: 16.6s\tremaining: 14.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:14] 1700:\ttest: 0.7975288\tbest: 0.7975371 (1695)\ttotal: 17.4s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7975288\tbest: 0.7975371 (1695)\ttotal: 17.4s\tremaining: 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:15] 1800:\ttest: 0.7979577\tbest: 0.7979577 (1800)\ttotal: 18.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7979577\tbest: 0.7979577 (1800)\ttotal: 18.1s\tremaining: 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:16] 1900:\ttest: 0.7983496\tbest: 0.7983498 (1899)\ttotal: 18.9s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7983496\tbest: 0.7983498 (1899)\ttotal: 18.9s\tremaining: 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:16] 2000:\ttest: 0.7986139\tbest: 0.7986151 (1999)\ttotal: 19.6s\tremaining: 9.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.7986139\tbest: 0.7986151 (1999)\ttotal: 19.6s\tremaining: 9.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:19] 2100:\ttest: 0.7990113\tbest: 0.7990113 (2100)\ttotal: 22.1s\tremaining: 9.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.7990113\tbest: 0.7990113 (2100)\ttotal: 22.1s\tremaining: 9.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:23] 2200:\ttest: 0.7993405\tbest: 0.7993405 (2200)\ttotal: 25.6s\tremaining: 9.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.7993405\tbest: 0.7993405 (2200)\ttotal: 25.6s\tremaining: 9.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:23] 2300:\ttest: 0.7996186\tbest: 0.7996186 (2300)\ttotal: 26.4s\tremaining: 8.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.7996186\tbest: 0.7996186 (2300)\ttotal: 26.4s\tremaining: 8.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:24] 2400:\ttest: 0.7999451\tbest: 0.7999451 (2400)\ttotal: 27.2s\tremaining: 6.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.7999451\tbest: 0.7999451 (2400)\ttotal: 27.2s\tremaining: 6.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:25] 2500:\ttest: 0.8001704\tbest: 0.8001757 (2496)\ttotal: 27.9s\tremaining: 5.57s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.8001704\tbest: 0.8001757 (2496)\ttotal: 27.9s\tremaining: 5.57s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:26] 2600:\ttest: 0.8004555\tbest: 0.8004707 (2592)\ttotal: 28.7s\tremaining: 4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.8004555\tbest: 0.8004707 (2592)\ttotal: 28.7s\tremaining: 4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:26] 2700:\ttest: 0.8007380\tbest: 0.8007380 (2700)\ttotal: 29.5s\tremaining: 3.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.8007380\tbest: 0.8007380 (2700)\ttotal: 29.5s\tremaining: 3.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:27] 2800:\ttest: 0.8008721\tbest: 0.8008728 (2799)\ttotal: 30.2s\tremaining: 2.15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\ttest: 0.8008721\tbest: 0.8008728 (2799)\ttotal: 30.2s\tremaining: 2.15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:28] 2900:\ttest: 0.8011377\tbest: 0.8011428 (2899)\ttotal: 31s\tremaining: 1.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\ttest: 0.8011377\tbest: 0.8011428 (2899)\ttotal: 31s\tremaining: 1.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:29] 2999:\ttest: 0.8013525\tbest: 0.8013563 (2995)\ttotal: 31.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\ttest: 0.8013525\tbest: 0.8013563 (2995)\ttotal: 31.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:29] bestTest = 0.8013563454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8013563454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:29] bestIteration = 2995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:29] Shrink model to first 2996 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2996 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:30] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:43] 0:\ttest: 0.6555857\tbest: 0.6555857 (0)\ttotal: 11.5ms\tremaining: 34.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6555857\tbest: 0.6555857 (0)\ttotal: 11.5ms\tremaining: 34.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:44] 100:\ttest: 0.7684040\tbest: 0.7684040 (100)\ttotal: 874ms\tremaining: 25.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7684040\tbest: 0.7684040 (100)\ttotal: 874ms\tremaining: 25.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:45] 200:\ttest: 0.7822080\tbest: 0.7822080 (200)\ttotal: 1.64s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7822080\tbest: 0.7822080 (200)\ttotal: 1.64s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:46] 300:\ttest: 0.7898300\tbest: 0.7898300 (300)\ttotal: 2.42s\tremaining: 21.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7898300\tbest: 0.7898300 (300)\ttotal: 2.42s\tremaining: 21.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:46] 400:\ttest: 0.7938930\tbest: 0.7938930 (400)\ttotal: 3.23s\tremaining: 21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7938930\tbest: 0.7938930 (400)\ttotal: 3.23s\tremaining: 21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:47] 500:\ttest: 0.7964842\tbest: 0.7964842 (500)\ttotal: 3.99s\tremaining: 19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7964842\tbest: 0.7964842 (500)\ttotal: 3.99s\tremaining: 19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:48] 600:\ttest: 0.7985758\tbest: 0.7985758 (600)\ttotal: 4.84s\tremaining: 19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7985758\tbest: 0.7985758 (600)\ttotal: 4.84s\tremaining: 19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:51] 700:\ttest: 0.8002269\tbest: 0.8002269 (700)\ttotal: 7.85s\tremaining: 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8002269\tbest: 0.8002269 (700)\ttotal: 7.85s\tremaining: 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:54] 800:\ttest: 0.8014694\tbest: 0.8014694 (800)\ttotal: 10.8s\tremaining: 29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8014694\tbest: 0.8014694 (800)\ttotal: 10.8s\tremaining: 29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:55] 900:\ttest: 0.8026216\tbest: 0.8026216 (900)\ttotal: 11.5s\tremaining: 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8026216\tbest: 0.8026216 (900)\ttotal: 11.5s\tremaining: 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:55] 1000:\ttest: 0.8032578\tbest: 0.8032590 (999)\ttotal: 12.3s\tremaining: 24.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8032578\tbest: 0.8032590 (999)\ttotal: 12.3s\tremaining: 24.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:56] 1100:\ttest: 0.8039187\tbest: 0.8039187 (1100)\ttotal: 13s\tremaining: 22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.8039187\tbest: 0.8039187 (1100)\ttotal: 13s\tremaining: 22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:57] 1200:\ttest: 0.8045601\tbest: 0.8045601 (1200)\ttotal: 13.8s\tremaining: 20.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.8045601\tbest: 0.8045601 (1200)\ttotal: 13.8s\tremaining: 20.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:58] 1300:\ttest: 0.8051415\tbest: 0.8051415 (1300)\ttotal: 14.6s\tremaining: 19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.8051415\tbest: 0.8051415 (1300)\ttotal: 14.6s\tremaining: 19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:58] 1400:\ttest: 0.8057441\tbest: 0.8057441 (1400)\ttotal: 15.3s\tremaining: 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.8057441\tbest: 0.8057441 (1400)\ttotal: 15.3s\tremaining: 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:24:59] 1500:\ttest: 0.8062494\tbest: 0.8062494 (1500)\ttotal: 16s\tremaining: 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.8062494\tbest: 0.8062494 (1500)\ttotal: 16s\tremaining: 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:00] 1600:\ttest: 0.8067756\tbest: 0.8067756 (1600)\ttotal: 16.8s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.8067756\tbest: 0.8067756 (1600)\ttotal: 16.8s\tremaining: 14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:01] 1700:\ttest: 0.8071809\tbest: 0.8071814 (1699)\ttotal: 17.6s\tremaining: 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.8071809\tbest: 0.8071814 (1699)\ttotal: 17.6s\tremaining: 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:02] 1800:\ttest: 0.8076319\tbest: 0.8076349 (1797)\ttotal: 18.3s\tremaining: 12.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.8076319\tbest: 0.8076349 (1797)\ttotal: 18.3s\tremaining: 12.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:02] 1900:\ttest: 0.8081060\tbest: 0.8081060 (1900)\ttotal: 19.1s\tremaining: 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.8081060\tbest: 0.8081060 (1900)\ttotal: 19.1s\tremaining: 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:03] 2000:\ttest: 0.8083279\tbest: 0.8083279 (2000)\ttotal: 19.8s\tremaining: 9.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.8083279\tbest: 0.8083279 (2000)\ttotal: 19.8s\tremaining: 9.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:05] 2100:\ttest: 0.8086482\tbest: 0.8086618 (2094)\ttotal: 21.2s\tremaining: 9.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.8086482\tbest: 0.8086618 (2094)\ttotal: 21.2s\tremaining: 9.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:08] 2200:\ttest: 0.8089733\tbest: 0.8089837 (2198)\ttotal: 24.5s\tremaining: 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.8089733\tbest: 0.8089837 (2198)\ttotal: 24.5s\tremaining: 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:10] 2300:\ttest: 0.8093745\tbest: 0.8093745 (2300)\ttotal: 26.8s\tremaining: 8.15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.8093745\tbest: 0.8093745 (2300)\ttotal: 26.8s\tremaining: 8.15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:11] 2400:\ttest: 0.8096837\tbest: 0.8096837 (2400)\ttotal: 27.6s\tremaining: 6.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.8096837\tbest: 0.8096837 (2400)\ttotal: 27.6s\tremaining: 6.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:12] 2500:\ttest: 0.8098778\tbest: 0.8098778 (2500)\ttotal: 28.3s\tremaining: 5.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.8098778\tbest: 0.8098778 (2500)\ttotal: 28.3s\tremaining: 5.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:12] 2600:\ttest: 0.8102005\tbest: 0.8102005 (2600)\ttotal: 29.1s\tremaining: 4.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.8102005\tbest: 0.8102005 (2600)\ttotal: 29.1s\tremaining: 4.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:13] 2700:\ttest: 0.8105219\tbest: 0.8105219 (2700)\ttotal: 29.8s\tremaining: 3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.8105219\tbest: 0.8105219 (2700)\ttotal: 29.8s\tremaining: 3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:14] 2800:\ttest: 0.8108211\tbest: 0.8108258 (2799)\ttotal: 30.6s\tremaining: 2.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\ttest: 0.8108211\tbest: 0.8108258 (2799)\ttotal: 30.6s\tremaining: 2.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:15] 2900:\ttest: 0.8110669\tbest: 0.8110778 (2894)\ttotal: 31.3s\tremaining: 1.07s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\ttest: 0.8110669\tbest: 0.8110778 (2894)\ttotal: 31.3s\tremaining: 1.07s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:15] 2999:\ttest: 0.8113253\tbest: 0.8113274 (2998)\ttotal: 32.1s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\ttest: 0.8113253\tbest: 0.8113274 (2998)\ttotal: 32.1s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:15] bestTest = 0.811327368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.811327368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:15] bestIteration = 2998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] Shrink model to first 2999 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2999 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m finished. score = \u001b[1m0.8055646286838106\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m finished. score = \u001b[1m0.8055646286838106\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] Time left 2153.21 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2153.21 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:16] Blending: optimization starts with equal weights and score \u001b[1m0.807498590458114\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.807498590458114\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:19] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8677039354869397\u001b[0m, weights = \u001b[1m[1. 0. 0. 0.]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8677039354869397\u001b[0m, weights = \u001b[1m[1. 0. 0. 0.]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:20] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8677039354869397\u001b[0m, weights = \u001b[1m[1. 0. 0. 0.]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8677039354869397\u001b[0m, weights = \u001b[1m[1. 0. 0. 0.]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:20] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:20] \u001b[1mAutoml preset training completed in 1450.86 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1450.86 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:25:20] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21min 3s, sys: 3min 18s, total: 24min 22s\n",
            "Wall time: 24min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_nan = np.any(~np.isnan(oof_pred_train_3.data), axis=1)\n",
        "\n",
        "print('Check scores:')\n",
        "print('Train scores: {}'.format(roc_auc_score(train_data[roles['target']].values[not_nan], oof_pred_train_3.data[not_nan][:, 0])))\n",
        "print('Validation scores: {}'.format(roc_auc_score(val_data[roles['target']].values, val_pred_train_3.data[:, 0])))"
      ],
      "metadata": {
        "id": "LGnmUP_vnE02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bf153e-fcce-47fb-a780-556c3d20ae77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "Train scores: 0.49961716872267836\n",
            "Validation scores: 0.5944670413469275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_train_3 = automl_3.predict(test_data)\n",
        "print('Test scores: {}'.format(roc_auc_score(test_labels[roles['target']].values, test_pred_train_3.data[:, 0])))"
      ],
      "metadata": {
        "id": "MwIkPv0lnRs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d96097-dd7d-456b-d1e9-b3af5abc44ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test scores: 0.5885277987183342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_submissions(test_pred_train_3, 'automl_based_train.csv')"
      ],
      "metadata": {
        "id": "bnx9L8gYnlf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оригинальный датасет (явно указываем валидационную выборку)"
      ],
      "metadata": {
        "id": "WIb8NT_hKPfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_pred_train_3_1 = automl_3.fit_predict(train_data.sample(frac=1), roles=roles, verbose = 10, valid_data=val_data)\n",
        "val_pred_train_3_1 = automl_3.predict(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9lGE5z4_TIf",
        "outputId": "0912eb97-a522-4dc7-fa82-442a547843b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] - CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] - memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] \u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:15] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.85 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3599.85 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:59] Linear model: C = 1e-05 score = 0.5925701024366226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5925701024366226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:00] Linear model: C = 5e-05 score = 0.5933844915997166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5933844915997166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:00] Linear model: C = 0.0001 score = 0.5936918014674977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5936918014674977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:00] Linear model: C = 0.0005 score = 0.5957227005800338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.5957227005800338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:01] Linear model: C = 0.001 score = 0.5973089070624827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.5973089070624827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:01] Linear model: C = 0.005 score = 0.60344333561504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.60344333561504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:02] Linear model: C = 0.01 score = 0.6048800302626365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6048800302626365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:02] Linear model: C = 0.05 score = 0.607324458695104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.607324458695104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:02] Linear model: C = 0.1 score = 0.607324458695104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.607324458695104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:03] Linear model: C = 0.5 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:03] Linear model: C = 1 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:04] Linear model: C = 5 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.6101184686145236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:04] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:27:04] Time left 3551.53 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3551.53 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:31:10] Feature concated__comment_text fitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text fitted\n",
            "100%|██████████| 209/209 [01:49<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:33:02] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n",
            "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:33:10] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:33:44] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:25] [100]\tvalid's auc: 0.526271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.526271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:26] Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.536268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.536268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:39] 0:\ttest: 0.5167571\tbest: 0.5167571 (0)\ttotal: 14.7ms\tremaining: 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5167571\tbest: 0.5167571 (0)\ttotal: 14.7ms\tremaining: 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:40] 100:\ttest: 0.5241152\tbest: 0.5364330 (7)\ttotal: 1.06s\tremaining: 20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5241152\tbest: 0.5364330 (7)\ttotal: 1.06s\tremaining: 20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:41] bestTest = 0.5364330113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5364330113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:41] bestIteration = 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:41] Shrink model to first 8 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 8 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:41] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-9b8e3c63-15bb-4151-9061-f02a8fe4e188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:54] 0:\ttest: 0.5230134\tbest: 0.5230134 (0)\ttotal: 12.3ms\tremaining: 24.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5230134\tbest: 0.5230134 (0)\ttotal: 12.3ms\tremaining: 24.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] 100:\ttest: 0.5245152\tbest: 0.5335414 (8)\ttotal: 922ms\tremaining: 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5245152\tbest: 0.5335414 (8)\ttotal: 922ms\tremaining: 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] bestTest = 0.533541441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.533541441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] bestIteration = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5335414490038549 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.5335414490038549.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:55] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.5335414490038549 in 0:00:14.706191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.5335414490038549 in 0:00:14.706191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:09] 0:\ttest: 0.5135702\tbest: 0.5135702 (0)\ttotal: 22.4ms\tremaining: 44.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5135702\tbest: 0.5135702 (0)\ttotal: 22.4ms\tremaining: 44.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] 100:\ttest: 0.5241954\tbest: 0.5350998 (8)\ttotal: 1.52s\tremaining: 28.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5241954\tbest: 0.5350998 (8)\ttotal: 1.52s\tremaining: 28.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] bestTest = 0.5350997746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5350997746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] bestIteration = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.5350997946463956 and parameters: {'max_depth': 7}. Best is trial 1 with value: 0.5350997946463956.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 7} scored 0.5350997946463956 in 0:00:15.812997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 7} scored 0.5350997946463956 in 0:00:15.812997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:11] The set of hyperparameters \u001b[1m{'max_depth': 7}\u001b[0m\n",
            " achieve 0.5351 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 7}\u001b[0m\n",
            " achieve 0.5351 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:24] 0:\ttest: 0.5135702\tbest: 0.5135702 (0)\ttotal: 22.6ms\tremaining: 1m 7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5135702\tbest: 0.5135702 (0)\ttotal: 22.6ms\tremaining: 1m 7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] 100:\ttest: 0.5235029\tbest: 0.5373976 (5)\ttotal: 1.54s\tremaining: 44.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5235029\tbest: 0.5373976 (5)\ttotal: 1.54s\tremaining: 44.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] bestTest = 0.5373975933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5373975933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] bestIteration = 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Shrink model to first 6 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Time left 2989.10 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2989.10 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Blending: optimization starts with equal weights and score \u001b[1m0.5754760961198977\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.5754760961198977\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.6213490290737472\u001b[0m, weights = \u001b[1m[0.6601549  0.15418068 0.         0.18566445]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.6213490290737472\u001b[0m, weights = \u001b[1m[0.6601549  0.15418068 0.         0.18566445]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.6215429741446602\u001b[0m, weights = \u001b[1m[0.6693633  0.18284358 0.         0.14779314]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.6215429741446602\u001b[0m, weights = \u001b[1m[0.6693633  0.18284358 0.         0.14779314]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:26] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.6215929915576852\u001b[0m, weights = \u001b[1m[0.6503215  0.21307619 0.         0.13660231]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.6215929915576852\u001b[0m, weights = \u001b[1m[0.6503215  0.21307619 0.         0.13660231]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:27] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.6215929915576852\u001b[0m, weights = \u001b[1m[0.6503215  0.21307619 0.         0.13660231]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.6215929915576852\u001b[0m, weights = \u001b[1m[0.6503215  0.21307619 0.         0.13660231]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:27] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:27] \u001b[1mAutoml preset training completed in 611.57 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 611.57 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:27] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.65032 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.21308 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.13660 * (1 averaged models Lvl_0_Pipe_1_Mod_3_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.65032 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.21308 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.13660 * (1 averaged models Lvl_0_Pipe_1_Mod_3_CatBoost) \n",
            "\n",
            "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:36:33] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9min 36s, sys: 18.5 s, total: 9min 54s\n",
            "Wall time: 10min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Check scores:')\n",
        "print('Validation scores: {}'.format(roc_auc_score(val_data[roles['target']].values, val_pred_train_3_1.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxMDs0m6FV9c",
        "outputId": "61b68aab-feb0-49b4-f895-50bf1dfda272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "Validation scores: 0.6215929915576852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_train_3_1 = automl_3.predict(test_data)\n",
        "print('Test scores: {}'.format(roc_auc_score(test_labels[roles['target']].values, test_pred_train_3_1.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drWEeGcYHzlm",
        "outputId": "7c9f0b13-05d1-46fe-b1ae-32418f75735a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:42:13] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test scores: 0.614309527093237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_submissions(test_pred_train_3_1, 'automl_based_train_1.csv')"
      ],
      "metadata": {
        "id": "M9aKKL4cIJ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработанные данные"
      ],
      "metadata": {
        "id": "lcTpoYOjnxbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_pred_preprocessed_3 = automl_3.fit_predict(preprocessed_data.sample(frac=1), roles=roles, verbose = 10)\n",
        "val_pred_preprocessed_3 = automl_3.predict(val_data)"
      ],
      "metadata": {
        "id": "h-9kIJcm0ySR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0452585-5275-4146-982b-72735a392ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] - CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 1 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] - memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] \u001b[1mTrain data shape: (1842, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1842, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:52] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.97 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3599.97 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 1e-05 score = 0.8885981497737863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8885981497737863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 5e-05 score = 0.8864541832669323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8864541832669323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 0.0001 score = 0.8864204200148558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8864204200148558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 1e-05 score = 0.8782689075630252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8782689075630252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 5e-05 score = 0.8769915966386553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8769915966386553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 0.0001 score = 0.8769915966386554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8769915966386554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 1e-05 score = 0.8980338983050847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8980338983050847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 5e-05 score = 0.8970847457627119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8970847457627119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 0.0001 score = 0.8970847457627119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8970847457627119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 1e-05 score = 0.8696101694915255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8696101694915255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 5e-05 score = 0.8673898305084745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8673898305084745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 0.0001 score = 0.8673559322033898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8673559322033898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 1e-05 score = 0.9193898305084747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.9193898305084747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 5e-05 score = 0.9178983050847458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.9178983050847458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Linear model: C = 0.0001 score = 0.9178474576271187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.9178474576271187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.6240395162719232\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.6240395162719232\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:54] Time left 3598.16 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3598.16 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:44:59] Feature concated__comment_text fitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text fitted\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:02] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:02] Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 1, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 1, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:02] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:02] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:05] [100]\tvalid's auc: 0.835911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.835911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:09] [200]\tvalid's auc: 0.845331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.845331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:11] [300]\tvalid's auc: 0.852218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.852218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:14] [400]\tvalid's auc: 0.858701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.858701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:17] [500]\tvalid's auc: 0.863124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.863124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:20] [600]\tvalid's auc: 0.865757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.865757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:24] [700]\tvalid's auc: 0.867952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.867952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:26] [800]\tvalid's auc: 0.869606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.869606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:29] [900]\tvalid's auc: 0.870045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.870045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:31] [1000]\tvalid's auc: 0.870282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.870282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:34] [1100]\tvalid's auc: 0.871868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.871868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:37] [1200]\tvalid's auc: 0.873388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.873388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:40] [1300]\tvalid's auc: 0.873962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.873962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:42] [1400]\tvalid's auc: 0.873894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's auc: 0.873894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:44] [1500]\tvalid's auc: 0.87511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's auc: 0.87511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:46] [1600]\tvalid's auc: 0.875211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's auc: 0.875211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:48] [1700]\tvalid's auc: 0.874603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1700]\tvalid's auc: 0.874603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:50] [1800]\tvalid's auc: 0.874502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1800]\tvalid's auc: 0.874502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:51] Early stopping, best iteration is:\n",
            "[1641]\tvalid's auc: 0.875549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1641]\tvalid's auc: 0.875549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:51] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:55] [100]\tvalid's auc: 0.807563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.807563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:45:57] [200]\tvalid's auc: 0.814924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.814924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:00] [300]\tvalid's auc: 0.820504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.820504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:02] [400]\tvalid's auc: 0.82437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.82437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:06] [500]\tvalid's auc: 0.828067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.828067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:10] [600]\tvalid's auc: 0.829815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.829815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:12] [700]\tvalid's auc: 0.829916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.829916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:14] [800]\tvalid's auc: 0.831092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.831092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:17] [900]\tvalid's auc: 0.831025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.831025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:20] [1000]\tvalid's auc: 0.831697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.831697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:23] [1100]\tvalid's auc: 0.831025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.831025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:24] Early stopping, best iteration is:\n",
            "[932]\tvalid's auc: 0.831798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[932]\tvalid's auc: 0.831798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:24] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:24] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:27] [100]\tvalid's auc: 0.812475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.812475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:29] [200]\tvalid's auc: 0.823492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.823492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:32] [300]\tvalid's auc: 0.833695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.833695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:35] [400]\tvalid's auc: 0.839695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.839695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:39] [500]\tvalid's auc: 0.844542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.844542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:42] [600]\tvalid's auc: 0.847831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.847831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:44] [700]\tvalid's auc: 0.848576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.848576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:47] [800]\tvalid's auc: 0.850475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.850475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:49] [900]\tvalid's auc: 0.852644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.852644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:53] [1000]\tvalid's auc: 0.852983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.852983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:56] [1100]\tvalid's auc: 0.853627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.853627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:46:58] [1200]\tvalid's auc: 0.853424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.853424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:00] [1300]\tvalid's auc: 0.85322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.85322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:01] Early stopping, best iteration is:\n",
            "[1155]\tvalid's auc: 0.854068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1155]\tvalid's auc: 0.854068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:01] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:02] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:04] [100]\tvalid's auc: 0.847966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:08] [200]\tvalid's auc: 0.853254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.853254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:11] [300]\tvalid's auc: 0.85878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.85878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:14] [400]\tvalid's auc: 0.861288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.861288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:16] [500]\tvalid's auc: 0.862407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.862407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:19] [600]\tvalid's auc: 0.864746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.864746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:23] [700]\tvalid's auc: 0.865051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.865051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:26] Early stopping, best iteration is:\n",
            "[594]\tvalid's auc: 0.865288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[594]\tvalid's auc: 0.865288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:26] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:26] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:29] [100]\tvalid's auc: 0.832542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.832542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:31] [200]\tvalid's auc: 0.843492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.843492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:34] [300]\tvalid's auc: 0.852136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.852136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:38] [400]\tvalid's auc: 0.856475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.856475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:41] [500]\tvalid's auc: 0.858576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.858576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:44] [600]\tvalid's auc: 0.859424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.859424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:46] [700]\tvalid's auc: 0.859424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.859424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:49] [800]\tvalid's auc: 0.859492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.859492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] Early stopping, best iteration is:\n",
            "[675]\tvalid's auc: 0.86061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[675]\tvalid's auc: 0.86061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.852785115393303\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.852785115393303\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:51] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:52] 0:\ttest: 0.7386387\tbest: 0.7386387 (0)\ttotal: 42.6ms\tremaining: 21.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7386387\tbest: 0.7386387 (0)\ttotal: 42.6ms\tremaining: 21.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:55] 100:\ttest: 0.8231143\tbest: 0.8231143 (100)\ttotal: 2.56s\tremaining: 10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8231143\tbest: 0.8231143 (100)\ttotal: 2.56s\tremaining: 10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:56] 200:\ttest: 0.8425282\tbest: 0.8428658 (199)\ttotal: 3.22s\tremaining: 4.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8425282\tbest: 0.8428658 (199)\ttotal: 3.22s\tremaining: 4.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:56] 300:\ttest: 0.8473226\tbest: 0.8473226 (300)\ttotal: 3.81s\tremaining: 2.52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8473226\tbest: 0.8473226 (300)\ttotal: 3.81s\tremaining: 2.52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:57] 400:\ttest: 0.8467149\tbest: 0.8506314 (367)\ttotal: 4.41s\tremaining: 1.09s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8467149\tbest: 0.8506314 (367)\ttotal: 4.41s\tremaining: 1.09s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:57] bestTest = 0.8506313562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506313562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:57] bestIteration = 367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:57] Shrink model to first 368 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 368 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:57] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:58] 0:\ttest: 0.7222017\tbest: 0.7222017 (0)\ttotal: 6.96ms\tremaining: 3.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7222017\tbest: 0.7222017 (0)\ttotal: 6.96ms\tremaining: 3.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:58] 100:\ttest: 0.7965042\tbest: 0.7972773 (98)\ttotal: 579ms\tremaining: 2.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7965042\tbest: 0.7972773 (98)\ttotal: 579ms\tremaining: 2.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:59] 200:\ttest: 0.8087731\tbest: 0.8088740 (187)\ttotal: 1.12s\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8087731\tbest: 0.8088740 (187)\ttotal: 1.12s\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] 300:\ttest: 0.8152269\tbest: 0.8152269 (300)\ttotal: 1.72s\tremaining: 1.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8152269\tbest: 0.8152269 (300)\ttotal: 1.72s\tremaining: 1.14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] 400:\ttest: 0.8145546\tbest: 0.8155966 (306)\ttotal: 2.3s\tremaining: 569ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8145546\tbest: 0.8155966 (306)\ttotal: 2.3s\tremaining: 569ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] bestTest = 0.8155966401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8155966401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] bestIteration = 306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] Shrink model to first 307 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 307 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:00] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:01] 0:\ttest: 0.7361864\tbest: 0.7361864 (0)\ttotal: 6.87ms\tremaining: 3.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7361864\tbest: 0.7361864 (0)\ttotal: 6.87ms\tremaining: 3.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:02] 100:\ttest: 0.8211864\tbest: 0.8216610 (98)\ttotal: 571ms\tremaining: 2.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8211864\tbest: 0.8216610 (98)\ttotal: 571ms\tremaining: 2.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:02] 200:\ttest: 0.8349831\tbest: 0.8349831 (200)\ttotal: 1.1s\tremaining: 1.64s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8349831\tbest: 0.8349831 (200)\ttotal: 1.1s\tremaining: 1.64s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:03] 300:\ttest: 0.8401356\tbest: 0.8410847 (266)\ttotal: 1.67s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8401356\tbest: 0.8410847 (266)\ttotal: 1.67s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:03] 400:\ttest: 0.8475593\tbest: 0.8487458 (387)\ttotal: 2.23s\tremaining: 550ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8475593\tbest: 0.8487458 (387)\ttotal: 2.23s\tremaining: 550ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:04] 499:\ttest: 0.8499322\tbest: 0.8505763 (490)\ttotal: 2.8s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8499322\tbest: 0.8505763 (490)\ttotal: 2.8s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:04] bestTest = 0.8505762815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8505762815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:04] bestIteration = 490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:04] Shrink model to first 491 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 491 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:04] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:05] 0:\ttest: 0.7576779\tbest: 0.7576779 (0)\ttotal: 33.6ms\tremaining: 16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7576779\tbest: 0.7576779 (0)\ttotal: 33.6ms\tremaining: 16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:08] 100:\ttest: 0.8475932\tbest: 0.8483390 (91)\ttotal: 3.14s\tremaining: 12.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8475932\tbest: 0.8483390 (91)\ttotal: 3.14s\tremaining: 12.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:11] 200:\ttest: 0.8612881\tbest: 0.8614237 (198)\ttotal: 5.33s\tremaining: 7.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8612881\tbest: 0.8614237 (198)\ttotal: 5.33s\tremaining: 7.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:11] 300:\ttest: 0.8660339\tbest: 0.8662034 (286)\ttotal: 5.98s\tremaining: 3.95s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8660339\tbest: 0.8662034 (286)\ttotal: 5.98s\tremaining: 3.95s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:12] 400:\ttest: 0.8662373\tbest: 0.8667797 (339)\ttotal: 6.57s\tremaining: 1.62s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8662373\tbest: 0.8667797 (339)\ttotal: 6.57s\tremaining: 1.62s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] 499:\ttest: 0.8668475\tbest: 0.8687797 (477)\ttotal: 7.15s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8668475\tbest: 0.8687797 (477)\ttotal: 7.15s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] bestTest = 0.8687796593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8687796593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] bestIteration = 477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] Shrink model to first 478 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 478 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:13] 0:\ttest: 0.6770169\tbest: 0.6770169 (0)\ttotal: 6.88ms\tremaining: 3.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6770169\tbest: 0.6770169 (0)\ttotal: 6.88ms\tremaining: 3.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:14] 100:\ttest: 0.8348814\tbest: 0.8349491 (98)\ttotal: 549ms\tremaining: 2.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8348814\tbest: 0.8349491 (98)\ttotal: 549ms\tremaining: 2.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:14] 200:\ttest: 0.8458644\tbest: 0.8458644 (200)\ttotal: 1.11s\tremaining: 1.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8458644\tbest: 0.8458644 (200)\ttotal: 1.11s\tremaining: 1.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:15] 300:\ttest: 0.8538305\tbest: 0.8538305 (289)\ttotal: 1.67s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8538305\tbest: 0.8538305 (289)\ttotal: 1.67s\tremaining: 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] 400:\ttest: 0.8576610\tbest: 0.8586441 (392)\ttotal: 2.25s\tremaining: 556ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8576610\tbest: 0.8586441 (392)\ttotal: 2.25s\tremaining: 556ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] 499:\ttest: 0.8606440\tbest: 0.8610169 (466)\ttotal: 2.83s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8606440\tbest: 0.8610169 (466)\ttotal: 2.83s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] bestTest = 0.8610169291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8610169291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] bestIteration = 466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] Shrink model to first 467 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 467 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8473613664060292\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8473613664060292\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ... Time budget is 30.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-dd22ef79-fa21-4063-bc40-c6575c70e48d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:17] 0:\ttest: 0.7258424\tbest: 0.7258424 (0)\ttotal: 5.89ms\tremaining: 2.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7258424\tbest: 0.7258424 (0)\ttotal: 5.89ms\tremaining: 2.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:18] 100:\ttest: 0.8253089\tbest: 0.8254778 (99)\ttotal: 488ms\tremaining: 1.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8253089\tbest: 0.8254778 (99)\ttotal: 488ms\tremaining: 1.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:18] 200:\ttest: 0.8390843\tbest: 0.8401985 (185)\ttotal: 1.01s\tremaining: 1.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8390843\tbest: 0.8401985 (185)\ttotal: 1.01s\tremaining: 1.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:19] 300:\ttest: 0.8487406\tbest: 0.8487744 (299)\ttotal: 1.51s\tremaining: 998ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8487406\tbest: 0.8487744 (299)\ttotal: 1.51s\tremaining: 998ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:19] 400:\ttest: 0.8494496\tbest: 0.8505976 (397)\ttotal: 2.04s\tremaining: 505ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8494496\tbest: 0.8505976 (397)\ttotal: 2.04s\tremaining: 505ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] 499:\ttest: 0.8535350\tbest: 0.8540415 (453)\ttotal: 2.56s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8535350\tbest: 0.8540415 (453)\ttotal: 2.56s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] bestTest = 0.8540414572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8540414572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] bestIteration = 453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] Shrink model to first 454 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 454 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.8540414612735499 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.8540414612735499.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:20] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.8540414612735499 in 0:00:03.639198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4} scored 0.8540414612735499 in 0:00:03.639198\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:22] 0:\ttest: 0.7581032\tbest: 0.7581032 (0)\ttotal: 56ms\tremaining: 28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7581032\tbest: 0.7581032 (0)\ttotal: 56ms\tremaining: 28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:26] 100:\ttest: 0.8533325\tbest: 0.8550544 (97)\ttotal: 4.14s\tremaining: 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8533325\tbest: 0.8550544 (97)\ttotal: 4.14s\tremaining: 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:27] 200:\ttest: 0.8594773\tbest: 0.8624822 (192)\ttotal: 5.01s\tremaining: 7.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8594773\tbest: 0.8624822 (192)\ttotal: 5.01s\tremaining: 7.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:28] 300:\ttest: 0.8626173\tbest: 0.8637990 (288)\ttotal: 5.84s\tremaining: 3.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8626173\tbest: 0.8637990 (288)\ttotal: 5.84s\tremaining: 3.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] 400:\ttest: 0.8633264\tbest: 0.8658586 (327)\ttotal: 6.71s\tremaining: 1.66s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8633264\tbest: 0.8658586 (327)\ttotal: 6.71s\tremaining: 1.66s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] bestTest = 0.8658586144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8658586144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] bestIteration = 327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] Shrink model to first 328 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 328 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.8658585995003037 and parameters: {'max_depth': 7}. Best is trial 1 with value: 0.8658585995003037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:29] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 7} scored 0.8658585995003037 in 0:00:09.309734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 7} scored 0.8658585995003037 in 0:00:09.309734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:30] 0:\ttest: 0.7593862\tbest: 0.7593862 (0)\ttotal: 8.13ms\tremaining: 4.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7593862\tbest: 0.7593862 (0)\ttotal: 8.13ms\tremaining: 4.06s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:31] 100:\ttest: 0.8329057\tbest: 0.8329057 (100)\ttotal: 672ms\tremaining: 2.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8329057\tbest: 0.8329057 (100)\ttotal: 672ms\tremaining: 2.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:32] 200:\ttest: 0.8414815\tbest: 0.8426970 (196)\ttotal: 1.32s\tremaining: 1.96s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8414815\tbest: 0.8426970 (196)\ttotal: 1.32s\tremaining: 1.96s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:32] 300:\ttest: 0.8461409\tbest: 0.8470187 (261)\ttotal: 1.99s\tremaining: 1.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8461409\tbest: 0.8470187 (261)\ttotal: 1.99s\tremaining: 1.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:33] 400:\ttest: 0.8554933\tbest: 0.8554933 (400)\ttotal: 2.65s\tremaining: 655ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8554933\tbest: 0.8554933 (400)\ttotal: 2.65s\tremaining: 655ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] 499:\ttest: 0.8601864\tbest: 0.8603889 (498)\ttotal: 3.28s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8601864\tbest: 0.8603889 (498)\ttotal: 3.28s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] bestTest = 0.8603889346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8603889346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] bestIteration = 498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] Shrink model to first 499 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 499 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.8603889526639207 and parameters: {'max_depth': 6}. Best is trial 1 with value: 0.8658585995003037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:34] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 6} scored 0.8603889526639207 in 0:00:04.433242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 6} scored 0.8603889526639207 in 0:00:04.433242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:35] 0:\ttest: 0.7386387\tbest: 0.7386387 (0)\ttotal: 7.14ms\tremaining: 3.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7386387\tbest: 0.7386387 (0)\ttotal: 7.14ms\tremaining: 3.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:35] 100:\ttest: 0.8231143\tbest: 0.8231143 (100)\ttotal: 584ms\tremaining: 2.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8231143\tbest: 0.8231143 (100)\ttotal: 584ms\tremaining: 2.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:36] 200:\ttest: 0.8425282\tbest: 0.8428658 (199)\ttotal: 1.12s\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8425282\tbest: 0.8428658 (199)\ttotal: 1.12s\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:37] 300:\ttest: 0.8473226\tbest: 0.8473226 (300)\ttotal: 2.76s\tremaining: 1.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8473226\tbest: 0.8473226 (300)\ttotal: 2.76s\tremaining: 1.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:41] 400:\ttest: 0.8467149\tbest: 0.8506314 (367)\ttotal: 6.31s\tremaining: 1.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8467149\tbest: 0.8506314 (367)\ttotal: 6.31s\tremaining: 1.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:42] bestTest = 0.8506313562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506313562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:42] bestIteration = 367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:42] Shrink model to first 368 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 368 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:42] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.8506313728138294 and parameters: {'max_depth': 5}. Best is trial 1 with value: 0.8658585995003037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:42] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 5} scored 0.8506313728138294 in 0:00:08.355062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 5} scored 0.8506313728138294 in 0:00:08.355062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:43] 0:\ttest: 0.7295395\tbest: 0.7295395 (0)\ttotal: 5.73ms\tremaining: 2.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7295395\tbest: 0.7295395 (0)\ttotal: 5.73ms\tremaining: 2.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:44] 100:\ttest: 0.8147073\tbest: 0.8147073 (100)\ttotal: 423ms\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8147073\tbest: 0.8147073 (100)\ttotal: 423ms\tremaining: 1.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:44] 200:\ttest: 0.8269633\tbest: 0.8269633 (200)\ttotal: 893ms\tremaining: 1.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8269633\tbest: 0.8269633 (200)\ttotal: 893ms\tremaining: 1.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:45] 300:\ttest: 0.8365521\tbest: 0.8366534 (298)\ttotal: 1.37s\tremaining: 906ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8365521\tbest: 0.8366534 (298)\ttotal: 1.37s\tremaining: 906ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:45] 400:\ttest: 0.8418867\tbest: 0.8425620 (380)\ttotal: 1.85s\tremaining: 457ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8418867\tbest: 0.8425620 (380)\ttotal: 1.85s\tremaining: 457ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:46] 499:\ttest: 0.8453643\tbest: 0.8453643 (499)\ttotal: 2.31s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8453643\tbest: 0.8453643 (499)\ttotal: 2.31s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:46] bestTest = 0.8453643322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8453643322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:46] bestIteration = 499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:46] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.8453643054899047 and parameters: {'max_depth': 3}. Best is trial 1 with value: 0.8658585995003037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:46] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 3} scored 0.8453643054899047 in 0:00:03.797106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 3} scored 0.8453643054899047 in 0:00:03.797106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:47] 0:\ttest: 0.7295395\tbest: 0.7295395 (0)\ttotal: 5.32ms\tremaining: 2.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7295395\tbest: 0.7295395 (0)\ttotal: 5.32ms\tremaining: 2.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:47] 100:\ttest: 0.8147073\tbest: 0.8147073 (100)\ttotal: 426ms\tremaining: 1.68s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8147073\tbest: 0.8147073 (100)\ttotal: 426ms\tremaining: 1.68s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:48] 200:\ttest: 0.8269633\tbest: 0.8269633 (200)\ttotal: 889ms\tremaining: 1.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8269633\tbest: 0.8269633 (200)\ttotal: 889ms\tremaining: 1.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:48] 300:\ttest: 0.8365521\tbest: 0.8366534 (298)\ttotal: 1.34s\tremaining: 886ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8365521\tbest: 0.8366534 (298)\ttotal: 1.34s\tremaining: 886ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] 400:\ttest: 0.8418867\tbest: 0.8425620 (380)\ttotal: 1.83s\tremaining: 451ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8418867\tbest: 0.8425620 (380)\ttotal: 1.83s\tremaining: 451ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] 499:\ttest: 0.8453643\tbest: 0.8453643 (499)\ttotal: 2.3s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8453643\tbest: 0.8453643 (499)\ttotal: 2.3s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] bestTest = 0.8453643322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8453643322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] bestIteration = 499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.8453643054899047 and parameters: {'max_depth': 3}. Best is trial 1 with value: 0.8658585995003037.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3} scored 0.8453643054899047 in 0:00:03.350224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3} scored 0.8453643054899047 in 0:00:03.350224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] The set of hyperparameters \u001b[1m{'max_depth': 7}\u001b[0m\n",
            " achieve 0.8659 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 7}\u001b[0m\n",
            " achieve 0.8659 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 7, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'GPU', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 7, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:50] 0:\ttest: 0.7581032\tbest: 0.7581032 (0)\ttotal: 9.19ms\tremaining: 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7581032\tbest: 0.7581032 (0)\ttotal: 9.19ms\tremaining: 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:51] 100:\ttest: 0.8315551\tbest: 0.8359444 (95)\ttotal: 830ms\tremaining: 23.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8315551\tbest: 0.8359444 (95)\ttotal: 830ms\tremaining: 23.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:53] 200:\ttest: 0.8485718\tbest: 0.8485718 (200)\ttotal: 2.87s\tremaining: 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8485718\tbest: 0.8485718 (200)\ttotal: 2.87s\tremaining: 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:57] 300:\ttest: 0.8549868\tbest: 0.8558647 (294)\ttotal: 6.76s\tremaining: 1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8549868\tbest: 0.8558647 (294)\ttotal: 6.76s\tremaining: 1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:58] bestTest = 0.8558647037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8558647037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:58] bestIteration = 294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:58] Shrink model to first 295 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 295 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:58] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:59] 0:\ttest: 0.6819160\tbest: 0.6819160 (0)\ttotal: 9.4ms\tremaining: 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6819160\tbest: 0.6819160 (0)\ttotal: 9.4ms\tremaining: 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:00] 100:\ttest: 0.8080000\tbest: 0.8087395 (99)\ttotal: 832ms\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8080000\tbest: 0.8087395 (99)\ttotal: 832ms\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:01] 200:\ttest: 0.8154622\tbest: 0.8178487 (155)\ttotal: 1.72s\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8154622\tbest: 0.8178487 (155)\ttotal: 1.72s\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:01] 300:\ttest: 0.8166050\tbest: 0.8213109 (244)\ttotal: 2.56s\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8166050\tbest: 0.8213109 (244)\ttotal: 2.56s\tremaining: 22.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:02] bestTest = 0.8213109374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8213109374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:02] bestIteration = 244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:02] Shrink model to first 245 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 245 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:02] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:02] 0:\ttest: 0.7142203\tbest: 0.7142203 (0)\ttotal: 9.8ms\tremaining: 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7142203\tbest: 0.7142203 (0)\ttotal: 9.8ms\tremaining: 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:03] 100:\ttest: 0.8320339\tbest: 0.8353559 (93)\ttotal: 849ms\tremaining: 24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8320339\tbest: 0.8353559 (93)\ttotal: 849ms\tremaining: 24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:04] 200:\ttest: 0.8414237\tbest: 0.8418983 (196)\ttotal: 1.66s\tremaining: 23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8414237\tbest: 0.8418983 (196)\ttotal: 1.66s\tremaining: 23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:05] 300:\ttest: 0.8475593\tbest: 0.8475593 (300)\ttotal: 2.51s\tremaining: 22.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8475593\tbest: 0.8475593 (300)\ttotal: 2.51s\tremaining: 22.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:06] 400:\ttest: 0.8486102\tbest: 0.8502373 (348)\ttotal: 3.33s\tremaining: 21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8486102\tbest: 0.8502373 (348)\ttotal: 3.33s\tremaining: 21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:07] 500:\ttest: 0.8522712\tbest: 0.8533559 (467)\ttotal: 4.17s\tremaining: 20.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8522712\tbest: 0.8533559 (467)\ttotal: 4.17s\tremaining: 20.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:09] 600:\ttest: 0.8520000\tbest: 0.8537966 (510)\ttotal: 6.36s\tremaining: 25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8520000\tbest: 0.8537966 (510)\ttotal: 6.36s\tremaining: 25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:09] bestTest = 0.8537966013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8537966013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:09] bestIteration = 510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:09] Shrink model to first 511 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 511 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:09] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n",
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:11] 0:\ttest: 0.7659152\tbest: 0.7659152 (0)\ttotal: 38.5ms\tremaining: 1m 55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7659152\tbest: 0.7659152 (0)\ttotal: 38.5ms\tremaining: 1m 55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:13] 100:\ttest: 0.8527119\tbest: 0.8565763 (87)\ttotal: 2.5s\tremaining: 1m 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8527119\tbest: 0.8565763 (87)\ttotal: 2.5s\tremaining: 1m 11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:14] 200:\ttest: 0.8567119\tbest: 0.8593220 (186)\ttotal: 3.31s\tremaining: 46.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8567119\tbest: 0.8593220 (186)\ttotal: 3.31s\tremaining: 46.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:15] bestTest = 0.8593220115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8593220115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:15] bestIteration = 186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:15] Shrink model to first 187 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 187 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:15] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:16] 0:\ttest: 0.7138814\tbest: 0.7138814 (0)\ttotal: 13.9ms\tremaining: 41.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7138814\tbest: 0.7138814 (0)\ttotal: 13.9ms\tremaining: 41.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:17] 100:\ttest: 0.8338983\tbest: 0.8357288 (95)\ttotal: 886ms\tremaining: 25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8338983\tbest: 0.8357288 (95)\ttotal: 886ms\tremaining: 25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:18] 200:\ttest: 0.8408136\tbest: 0.8425085 (178)\ttotal: 1.71s\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8408136\tbest: 0.8425085 (178)\ttotal: 1.71s\tremaining: 23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:19] 300:\ttest: 0.8458305\tbest: 0.8481695 (282)\ttotal: 2.54s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8458305\tbest: 0.8481695 (282)\ttotal: 2.54s\tremaining: 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] bestTest = 0.8481695056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8481695056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] bestIteration = 282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Shrink model to first 283 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 283 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m finished. score = \u001b[1m0.8412829803838825\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m finished. score = \u001b[1m0.8412829803838825\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] \u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Time left 3332.70 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3332.70 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Blending: optimization starts with equal weights and score \u001b[1m0.8527945832843031\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8527945832843031\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8540768062369055\u001b[0m, weights = \u001b[1m[0.22120652 0.38295913 0.28827876 0.10755556]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8540768062369055\u001b[0m, weights = \u001b[1m[0.22120652 0.38295913 0.28827876 0.10755556]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.85407951134862\u001b[0m, weights = \u001b[1m[0.21344827 0.4046003  0.2781681  0.10378332]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.85407951134862\u001b[0m, weights = \u001b[1m[0.21344827 0.4046003  0.2781681  0.10378332]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.85407951134862\u001b[0m, weights = \u001b[1m[0.21344827 0.4046003  0.2781681  0.10378332]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.85407951134862\u001b[0m, weights = \u001b[1m[0.21344827 0.4046003  0.2781681  0.10378332]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] \u001b[1mAutoml preset training completed in 267.68 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 267.68 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:20] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.21345 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.40460 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.27817 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
            "\t 0.10378 * (5 averaged models Lvl_0_Pipe_1_Mod_3_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.21345 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.40460 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.27817 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
            "\t 0.10378 * (5 averaged models Lvl_0_Pipe_1_Mod_3_CatBoost) \n",
            "\n",
            "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:29] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 37s, sys: 44.6 s, total: 5min 21s\n",
            "Wall time: 4min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_nan = np.any(~np.isnan(oof_pred_preprocessed_3.data), axis=1)\n",
        "\n",
        "print('Check scores:')\n",
        "print('Train scores: {}'.format(roc_auc_score(preprocessed_data[roles['target']].values, oof_pred_preprocessed_3.data[:, 0])))\n",
        "print('Validation scores: {}'.format(roc_auc_score(val_data[roles['target']].values, val_pred_preprocessed_3.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9zPH02C6kXb",
        "outputId": "424e54d7-8972-4090-c869-abfe8f7d832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "Train scores: 0.4724856324754072\n",
            "Validation scores: 0.5782191279076749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итого:**\n",
        "\n",
        "- Оригинальный датасет, кросс-валидация\n",
        "  - *OOF scores*: 0.49961716872267836\n",
        "  - *Validation scores*: 0.5944670413469275\n",
        "  - *Test scores*: 0.5885277987183342\n",
        "\n",
        "- Оригинальный датасет, явно указана валидационная выборка\n",
        "  - *Validation scores*: **0.6215929915576852**\n",
        "  - *Test scores*: **0.614309527093237**\n",
        "\n",
        "- Предобработанные данные\n",
        "  - *Train scores*: 0.4724856324754072\n",
        "  - *Validation scores*: 0.5782191279076749"
      ],
      "metadata": {
        "id": "gE0paumYAL5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Подход 2 - BERT**"
      ],
      "metadata": {
        "id": "lab0O7HtTKVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=3600,\n",
        "    gpu_ids='0',\n",
        "    reader_params={'cv': 5, 'random_state': 42},\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'multi',\n",
        "        'bert_model': 'bert-base-multilingual-cased'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-3},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 7\n",
        "    },\n",
        "    memory_limit = 7\n",
        ")"
      ],
      "metadata": {
        "id": "_ozytk5cTHnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучающая выборка"
      ],
      "metadata": {
        "id": "UrblkYbNXVbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "oof_pred_train_1 = automl.fit_predict(train_data.sample(frac=1), roles=roles, verbose = 10, valid_data=val_data)\n",
        "val_pred_train_1 = automl.predict(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCKG4kHYXJCY",
        "outputId": "3e61d35f-c1bf-4387-d7de-e9a7a68f7b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] - memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:54] \u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:55] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.45 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3599.45 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:57] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:57] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:51:57] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:05:08] Epoch: 0, train loss: 0.32253700494766235, val loss: 0.43837130069732666, val metric: 0.5044573741158386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.32253700494766235, val loss: 0.43837130069732666, val metric: 0.5044573741158386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:38] Epoch: 1, train loss: 0.32238584756851196, val loss: 0.42962658405303955, val metric: 0.5010904156308919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.32238584756851196, val loss: 0.42962658405303955, val metric: 0.5010904156308919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:29] Epoch: 2, train loss: 0.32003849744796753, val loss: 0.43121224641799927, val metric: 0.4937654165315656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: 0.32003849744796753, val loss: 0.43121224641799927, val metric: 0.4937654165315656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] Time left -9459.12 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left -9459.12 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] \u001b[1mAutoml preset training completed in 13059.14 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13059.14 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:29:34] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3h 28min 30s, sys: 41 s, total: 3h 29min 11s\n",
            "Wall time: 3h 38min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation scores: {}'.format(roc_auc_score(val_data[roles['target']].values, val_pred_train_1.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrcRadw1BYU6",
        "outputId": "ef378706-e2eb-4b7c-d7ca-54a8f5d0eabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation scores: 0.5010904156308919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_train_1 = automl.predict(test_data)\n",
        "print('Test scores: {}'.format(roc_auc_score(test_labels[roles['target']].values, test_pred_train_1.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46gRnktDBaXh",
        "outputId": "f0068b42-66c3-4d81-fa5c-1fafa6f0cf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test scores: 0.4967793632103666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_submissions(test_pred_train_1, 'automl_bert_initial_b.csv')"
      ],
      "metadata": {
        "id": "Ob8PnQMDBc5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработанные данные"
      ],
      "metadata": {
        "id": "vDg2ZdcDXc04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итого:**\n",
        "\n",
        "Оригинальный датасет:\n",
        " - Validation scores: 0.5010904156308919\n",
        " - Test scores: 0.4967793632103666"
      ],
      "metadata": {
        "id": "Kwuc8uuDX8dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Подход 3 - Linear + Bert --- BERT Pooling**"
      ],
      "metadata": {
        "id": "01OeI4as0Nun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_1 = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=3600,\n",
        "    memory_limit = 7,\n",
        "    general_params={'nested_cv': False, 'use_algos': [['linear_l2', 'nn']]},\n",
        "    text_params={'lang': 'multi', 'bert_model': 'bert-base-multilingual-cased'},\n",
        "    reader_params={'cv': 5},\n",
        "    linear_pipeline_params={'text_features': 'embed'},\n",
        "    autonlp_params={\n",
        "        'model_name': 'pooled_bert',\n",
        "        'transformer_params': {\n",
        "            'model_params': {'pooling': 'mean'},\n",
        "            'dataset_params': {'max_length': 128},\n",
        "            'loader_params': {\n",
        "                'batch_size': 32,\n",
        "                'num_workers': 2\n",
        "             }\n",
        "        }\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 3e-5},\n",
        "        'lang': 'multi',\n",
        "        'path_to_save': '/content/drive/MyDrive/toxic_comments/models',\n",
        "        'bert_name': 'bert-base-multilingual-cased',\n",
        "        'pooling': 'mean',\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 10\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "3gOwSANGsFZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оригинальный датасет"
      ],
      "metadata": {
        "id": "T27bGxIO2vCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "val_pred_train_2 = automl_1.fit_predict(train_data.sample(frac=1), roles=roles, verbose = 10, valid_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fc4a5f440f814d36a516db384095c0dc",
            "e85f708d976b465a9593d5e4154b0242",
            "c8fa752716884a68bc4faff5f2d66bc2",
            "4c8df702e9454b60990bf8f13bab914b",
            "223dc378a1c94cbbb74f993d449a0037",
            "ac178f87ef154a44b95aef885aa1baf1",
            "a46342bc76984f28a5b6476decfa3fac",
            "c5afd47cf27846b89946eca5e1b28d00",
            "c2682c401d57426f92136dba7c345cfa",
            "68a6f4d9105b454eb7730041a641d351",
            "57e8aa27034b412bbfe63f08a2a3f272",
            "eb841467ec974c42939a8087b0cf415d",
            "c4bb9d57c937473baef23683d18549d1",
            "74e740929fbd4ac98afaf6601d409626",
            "eae2f8dc6cdc48fb9b0315a4330849e0",
            "1a165d3b3f704095aee42f190a5ea32e",
            "01e86f52c2e143328b493498d16ebed7",
            "58a395089fa3424b84473b38fa5a3ef8",
            "67d8b196a395493aaa18e211f8c3086a",
            "e155b0e860bf432895f619ff05cbd61c",
            "a26ad8022a5746a987847b200e8408c1",
            "7b5ffcc06b014affb7a551c020883541",
            "c484812b5529406e8baea09c48330514",
            "859bc1203b004c83adf4abf5a5395285",
            "30f4ce4e4fb44938b2c7e403f667c16b",
            "ccd55ba1e287410e9ed57e797df5afe9",
            "924b8e319bb54d92a1ec7df44df8a1be",
            "e01323e41d834fb3a3dbfe7b89d1b0fb",
            "d51f8ec8cd37456dabff0df268075288",
            "011ae70d661b4870acafb49da3b35c4f",
            "1e80b6b7397a4ffaab10845936309e50",
            "335902acda7046f0a0d1244c26066f82",
            "29aed23db37c4821be7bb1f8c126d4ee",
            "c0700025a9b04f3c96a1b7d18e476f31",
            "453d2663db5b4aceb1d3cea5515b75bb",
            "9a7a61664b334526bb75fb921b70fe51",
            "582139d64ef24898be1bad66fdf4fb17",
            "d5fd781a9c20487faab7a26e0706cc12",
            "9de6830cbcbe4afbbb705d68f3511f41",
            "cf2715123aeb4df8a92c8527ccf9eefd",
            "9de045e2c0274d3a8539b5499d4209c0",
            "887c4b91e4da470b80dfb2abd47e305e",
            "cb807e59fed54117a74d70043a66f967",
            "09671f330d6f4328af4bee14bab09b06",
            "b480b0fce61849368dee2427c1831309",
            "7df92c094cd249d1bcd7ab6841c07c54",
            "84e9d2c143794670924d71796e025af9",
            "32e5baf4118540298255fc4750ffbc8e",
            "6ee304bb360247ac8a133cfe3a014680",
            "1429e6a3fafe46ef8a4d892a16bff873",
            "0393bf690a864c4498eba989bb5978de",
            "bf32246cb94544eea586cfa171fe202e",
            "4dfc8d4b726245d68d65748d71339a1e",
            "b62927f97dff4eac855f71ebb222ff2a",
            "0e405797df294dc69ed1094fc1f34869"
          ]
        },
        "id": "8hR19kSKw2IT",
        "outputId": "5ff20f8d-d05c-4bac-bc46-cd54e40e303d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: multi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] - memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 7 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] \u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (213990, 2)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.80 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3599.80 secs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc4a5f440f814d36a516db384095c0dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb841467ec974c42939a8087b0cf415d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:55:09] Feature concated__comment_text fitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text fitted\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c484812b5529406e8baea09c48330514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0700025a9b04f3c96a1b7d18e476f31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b480b0fce61849368dee2427c1831309"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6688/6688 [24:49<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:20:03] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n",
            "100%|██████████| 250/250 [00:57<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:03] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:13] Linear model: C = 1e-05 score = 0.7971915793013175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7971915793013175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:15] Linear model: C = 5e-05 score = 0.8140192263813333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8140192263813333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:18] Linear model: C = 0.0001 score = 0.8096809213291543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8096809213291543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:24] Linear model: C = 0.0005 score = 0.7901336599776633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7901336599776633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:24] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:24] Time left 2014.89 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2014.89 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:27] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:27] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:21:27] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:38:28] Epoch: 0, train loss: 0.144016832113266, val loss: 0.3986031711101532, val metric: 0.8201632020751523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.144016832113266, val loss: 0.3986031711101532, val metric: 0.8201632020751523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:55:43] Epoch: 1, train loss: 0.10552743077278137, val loss: 0.5997905731201172, val metric: 0.7887561696148719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.10552743077278137, val loss: 0.5997905731201172, val metric: 0.7887561696148719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] \u001b[1mLvl_0_Pipe_1_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Time left -7278.87 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left -7278.87 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Blending: optimization starts with equal weights and score \u001b[1m0.8374283363956238\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8374283363956238\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8399286666426486\u001b[0m, weights = \u001b[1m[0.32580867 0.6741913 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8399286666426486\u001b[0m, weights = \u001b[1m[0.32580867 0.6741913 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8399286666426486\u001b[0m, weights = \u001b[1m[0.32580867 0.6741913 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8399286666426486\u001b[0m, weights = \u001b[1m[0.32580867 0.6741913 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] \u001b[1mAutoml preset training completed in 10879.25 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 10879.25 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:56:18] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.32581 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.67419 * (1 averaged models Lvl_0_Pipe_1_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.32581 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.67419 * (1 averaged models Lvl_0_Pipe_1_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2h 41min 36s, sys: 52.7 s, total: 2h 42min 28s\n",
            "Wall time: 3h 1min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Check scores. Initial')\n",
        "print('Validation scores: {}'.format(roc_auc_score(val_data[roles['target']].values, val_pred_train_2.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KiIPasuLH6e",
        "outputId": "547278aa-f486-4a2e-9235-a8f13808e89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores. Initial\n",
            "Validation scores: 0.8399286666426486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_train_2 = automl_1.predict(test_data)\n",
        "print('Test scores: {}'.format(roc_auc_score(test_labels[roles['target']].values, test_pred_train_2.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtNAsFzaTQRk",
        "outputId": "95c1e11c-36f4-42b3-8378-857fd00d8c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1995/1995 [07:37<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:03:59] Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.transformers.text:Feature concated__comment_text transformed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test scores: 0.8307054600643403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_submissions(test_pred_train_2, 'automl_bert_lin_train.csv')"
      ],
      "metadata": {
        "id": "5Gte59-8UBNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итого**\n",
        "\n",
        "Оригинальный датасет, явное указание валидационной выборки\n",
        "  - *Validation scores*: **0.8399286666426486**\n",
        "  - *Test scores*: **0.8307054600643403**"
      ],
      "metadata": {
        "id": "3LAZTx13_b6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Выводы**\n",
        "\n",
        "- Лучший скор на тестовой выборке: **0.83**.\n",
        "- Подход с комбинацией Linear и BERT дал скор значительно лучший, чемдва остальных подхода.\n",
        "- Обучение на небольшом датасете, который более похож на валидационную и тестовую выборки, чем оригинальный большой датасет, не дает преимуществ."
      ],
      "metadata": {
        "id": "_76oNtdbhQ8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Не LightAutoML подходы**"
      ],
      "metadata": {
        "id": "zOBoMl3Kv3Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ансамблирование трансформеров\n",
        "\n",
        "С использованием подбора гиперпараметров через optuna"
      ],
      "metadata": {
        "id": "LB5hMhudZqAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('accuracy')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "class HuggingFaceClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, model_name='bert-base-uncased', num_labels=2):\n",
        "        self.model_name = model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def objective(self, trial, model, tokenizer, train_dataset, val_dataset):\n",
        "        # Предложение гиперпараметров\n",
        "        learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n",
        "\n",
        "        # Определение аргументов тренировки\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='/content/drive/MyDrive/toxic_comments/opt',\n",
        "            learning_rate=learning_rate,\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=32,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "        )\n",
        "\n",
        "        # Инициализация Trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        # Обучение модели\n",
        "        trainer.train()\n",
        "\n",
        "        # Вычисление и возврат метрики для оптимизации\n",
        "        eval_result = trainer.evaluate()\n",
        "        metric_to_optimize = eval_result[\"eval_accuracy\"]\n",
        "\n",
        "        return metric_to_optimize\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        train_data_new = X[X['is_val'] == False]\n",
        "        val_data_new = X[X['is_val']]\n",
        "\n",
        "        train_data_new.loc[:, ('label')] = y[:len(train_data_new)]\n",
        "        train_inputs = self.tokenizer(train_data_new['comment_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_data_new['input_ids'] = pd.Series(train_inputs['input_ids'].tolist())\n",
        "        train_data_new['attention_mask'] = pd.Series(train_inputs['attention_mask'].tolist())\n",
        "        tds = Dataset.from_pandas(train_data_new)\n",
        "\n",
        "        val_data_new.loc[:, ('label')] = y[len(train_data_new):]\n",
        "        val_inputs = self.tokenizer(val_data_new['comment_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        val_data_new['input_ids'] = pd.Series(val_inputs['input_ids'].tolist())\n",
        "        val_data_new['attention_mask'] = pd.Series(val_inputs['attention_mask'].tolist())\n",
        "        vds = Dataset.from_pandas(train_data_new)\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.num_labels)\n",
        "\n",
        "        # Создание study object и запуск оптимизации\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lambda trial: self.objective(trial, model, self.tokenizer, Dataset.from_pandas(train_data_new.sample(frac=1)), vds), n_trials=2)\n",
        "\n",
        "        # Получение лучших гиперпараметров\n",
        "        best_params = study.best_params\n",
        "        print(f\"Best parameters for {self.model_name}: {best_params}\")\n",
        "\n",
        "        print(f\"Training {self.model_name}...\")\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='/content/drive/MyDrive/toxic_comments/results',\n",
        "            learning_rate=best_params['learning_rate'],\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=8,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=tds,\n",
        "            eval_dataset=vds,\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, data):\n",
        "        inputs = self.tokenizer(data['comment_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = self.model.to(device)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def predict_proba(self, data):\n",
        "        inputs = self.tokenizer(data['comment_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = self.model.to(device)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        probabilities = F.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        probabilities = probabilities.cpu().numpy()\n",
        "\n",
        "        return probabilities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqDAQp5YpFzP",
        "outputId": "cb6afe6b-cdcf-4aae-89b2-72216d2cb458"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ea5a79d15d00>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('accuracy')\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "classifiers = [\n",
        "    ('model1', HuggingFaceClassifier(model_name='distilbert-base-multilingual-cased')),\n",
        "    ('model2', HuggingFaceClassifier(model_name='roberta-base'))\n",
        "]\n",
        "\n",
        "ensemble = VotingClassifier(estimators=classifiers, voting='soft')"
      ],
      "metadata": {
        "id": "FEAtX1KSpMZw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data['is_val'] = False\n",
        "preprocessed_data['is_val'] = False\n",
        "val_data['is_val'] = True\n",
        "new_data = pd.concat([preprocessed_data, val_data], ignore_index=True)\n",
        "\n",
        "ensemble.fit(new_data[['comment_text', 'is_val']], new_data['toxic'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961,
          "referenced_widgets": [
            "206f2c1e370f495abf9894a591b1ae72",
            "dfec27f9173b4c82a78c1f95f71abf50",
            "6dc484d2813840fcb8b93fb25a958f24",
            "09e1ca965376432dae267fbd742dadb4",
            "ddba468618ed4ba89944501e67afc50b",
            "3afb9c56db7a4c28af53aae2b00b8b5c",
            "d8309b4557bc45dc88156bc5ee19242d",
            "9495c5dafa2c406abebcebc968ee62e7",
            "edcbabcce2d74af59dc750b73504ca91",
            "dddb4994b0ab4c44bd084150bebaac49",
            "d1643b5559f248b493265274964bf9bd"
          ]
        },
        "id": "_9RpAEjSp_J-",
        "outputId": "6ffb6f50-5eb1-4dc0-9437-8b10073d03b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-b0f825ac-240f-487b-a7a2-e9b5877a18e6\n",
            "<ipython-input-14-ea5a79d15d00>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1300072968006134, 'eval_accuracy': 0.9560260586319218, 'eval_runtime': 28.876, 'eval_samples_per_second': 63.79, 'eval_steps_per_second': 2.009, 'epoch': 1.0}\n",
            "{'eval_loss': 0.027239393442869186, 'eval_accuracy': 0.992942453854506, 'eval_runtime': 29.8931, 'eval_samples_per_second': 61.62, 'eval_steps_per_second': 1.94, 'epoch': 2.0}\n",
            "{'loss': 0.2082, 'learning_rate': 9.155073731486218e-06, 'epoch': 2.16}\n",
            "{'eval_loss': 0.002906771143898368, 'eval_accuracy': 0.998914223669924, 'eval_runtime': 29.3794, 'eval_samples_per_second': 62.697, 'eval_steps_per_second': 1.974, 'epoch': 3.0}\n",
            "{'train_runtime': 375.6408, 'train_samples_per_second': 14.711, 'train_steps_per_second': 1.845, 'train_loss': 0.1558948474873024, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.study.study:Trial 0 finished with value: 0.998914223669924 and parameters: {'learning_rate': 3.2872881326010096e-05}. Best is trial 0 with value: 0.998914223669924.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.002906771143898368, 'eval_accuracy': 0.998914223669924, 'eval_runtime': 29.6334, 'eval_samples_per_second': 62.16, 'eval_steps_per_second': 1.957, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ea5a79d15d00>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 6.012001176713966e-05, 'eval_accuracy': 1.0, 'eval_runtime': 29.8214, 'eval_samples_per_second': 61.768, 'eval_steps_per_second': 1.945, 'epoch': 1.0}\n",
            "{'eval_loss': 2.950089401565492e-05, 'eval_accuracy': 1.0, 'eval_runtime': 29.5274, 'eval_samples_per_second': 62.383, 'eval_steps_per_second': 1.964, 'epoch': 2.0}\n",
            "{'loss': 0.0086, 'learning_rate': 3.029682248962186e-06, 'epoch': 2.16}\n",
            "{'eval_loss': 2.306262103957124e-05, 'eval_accuracy': 1.0, 'eval_runtime': 29.6258, 'eval_samples_per_second': 62.175, 'eval_steps_per_second': 1.958, 'epoch': 3.0}\n",
            "{'train_runtime': 381.0482, 'train_samples_per_second': 14.502, 'train_steps_per_second': 1.819, 'train_loss': 0.006244879461889401, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.study.study:Trial 1 finished with value: 1.0 and parameters: {'learning_rate': 1.0878599992387538e-05}. Best is trial 1 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 2.306262103957124e-05, 'eval_accuracy': 1.0, 'eval_runtime': 29.6845, 'eval_samples_per_second': 62.053, 'eval_steps_per_second': 1.954, 'epoch': 3.0}\n",
            "Best parameters for distilbert-base-multilingual-cased: {'learning_rate': 1.0878599992387538e-05}\n",
            "Training distilbert-base-multilingual-cased...\n",
            "{'loss': 0.0086, 'learning_rate': 1.0878599992387538e-05, 'epoch': 2.16}\n",
            "{'train_runtime': 288.5881, 'train_samples_per_second': 19.148, 'train_steps_per_second': 2.401, 'train_loss': 0.013374554302441265, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "206f2c1e370f495abf9894a591b1ae72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-5db30476-878c-47ff-bef2-c50b90995a5a\n",
            "<ipython-input-14-ea5a79d15d00>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.4057259261608124, 'eval_accuracy': 0.8588490770901195, 'eval_runtime': 54.1422, 'eval_samples_per_second': 34.022, 'eval_steps_per_second': 1.071, 'epoch': 1.0}\n",
            "{'eval_loss': 0.1687816083431244, 'eval_accuracy': 0.9310532030401737, 'eval_runtime': 54.1671, 'eval_samples_per_second': 34.006, 'eval_steps_per_second': 1.071, 'epoch': 2.0}\n",
            "{'loss': 0.3266, 'learning_rate': 4.790935612323441e-06, 'epoch': 2.16}\n",
            "{'eval_loss': 0.12320435047149658, 'eval_accuracy': 0.9522258414766558, 'eval_runtime': 54.1014, 'eval_samples_per_second': 34.047, 'eval_steps_per_second': 1.072, 'epoch': 3.0}\n",
            "{'train_runtime': 670.8961, 'train_samples_per_second': 8.237, 'train_steps_per_second': 1.033, 'train_loss': 0.28950334799410116, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.study.study:Trial 0 finished with value: 0.9522258414766558 and parameters: {'learning_rate': 1.7202685903316812e-05}. Best is trial 0 with value: 0.9522258414766558.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.12320435047149658, 'eval_accuracy': 0.9522258414766558, 'eval_runtime': 54.1904, 'eval_samples_per_second': 33.991, 'eval_steps_per_second': 1.07, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ea5a79d15d00>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.33383628726005554, 'eval_accuracy': 0.9277958740499457, 'eval_runtime': 54.1059, 'eval_samples_per_second': 34.044, 'eval_steps_per_second': 1.072, 'epoch': 1.0}\n",
            "{'eval_loss': 0.10333548486232758, 'eval_accuracy': 0.9641693811074918, 'eval_runtime': 54.0499, 'eval_samples_per_second': 34.08, 'eval_steps_per_second': 1.073, 'epoch': 2.0}\n",
            "{'loss': 0.2657, 'learning_rate': 1.3396821463777511e-05, 'epoch': 2.16}\n",
            "{'eval_loss': 0.0512084923684597, 'eval_accuracy': 0.9858849077090119, 'eval_runtime': 54.097, 'eval_samples_per_second': 34.05, 'eval_steps_per_second': 1.072, 'epoch': 3.0}\n",
            "{'train_runtime': 672.313, 'train_samples_per_second': 8.219, 'train_steps_per_second': 1.031, 'train_loss': 0.22649654371913894, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:optuna.study.study:Trial 1 finished with value: 0.9858849077090119 and parameters: {'learning_rate': 4.8103612820714066e-05}. Best is trial 1 with value: 0.9858849077090119.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.0512084923684597, 'eval_accuracy': 0.9858849077090119, 'eval_runtime': 54.4342, 'eval_samples_per_second': 33.839, 'eval_steps_per_second': 1.066, 'epoch': 3.0}\n",
            "Best parameters for roberta-base: {'learning_rate': 4.8103612820714066e-05}\n",
            "Training roberta-base...\n",
            "{'loss': 0.1625, 'learning_rate': 4.8103612820714066e-05, 'epoch': 2.16}\n",
            "{'train_runtime': 504.8326, 'train_samples_per_second': 10.946, 'train_steps_per_second': 1.373, 'train_loss': 0.16237492031521267, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('model1',\n",
              "                              HuggingFaceClassifier(model_name='distilbert-base-multilingual-cased')),\n",
              "                             ('model2',\n",
              "                              HuggingFaceClassifier(model_name='roberta-base'))],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;model1&#x27;,\n",
              "                              HuggingFaceClassifier(model_name=&#x27;distilbert-base-multilingual-cased&#x27;)),\n",
              "                             (&#x27;model2&#x27;,\n",
              "                              HuggingFaceClassifier(model_name=&#x27;roberta-base&#x27;))],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;model1&#x27;,\n",
              "                              HuggingFaceClassifier(model_name=&#x27;distilbert-base-multilingual-cased&#x27;)),\n",
              "                             (&#x27;model2&#x27;,\n",
              "                              HuggingFaceClassifier(model_name=&#x27;roberta-base&#x27;))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HuggingFaceClassifier</label><div class=\"sk-toggleable__content\"><pre>HuggingFaceClassifier(model_name=&#x27;distilbert-base-multilingual-cased&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HuggingFaceClassifier</label><div class=\"sk-toggleable__content\"><pre>HuggingFaceClassifier(model_name=&#x27;roberta-base&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(ensemble, open('/content/drive/MyDrive/toxic_comments/ensemble_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "CXSdUXobevwf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = pickle.load(open('/content/drive/MyDrive/toxic_comments/ensemble_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "qZsk_Qj7e-iH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ensemble.predict_proba(val_data)"
      ],
      "metadata": {
        "id": "ZpbSAK6dqDX8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Check scores')\n",
        "print('Validation scores: {}'.format(roc_auc_score(val_data['toxic'].values, predictions[:, 0])))"
      ],
      "metadata": {
        "id": "MV8uKAyuivDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d6d206-98d7-4d7b-ad8b-f7e9f01ef9fd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores\n",
            "Validation scores: 0.9087164536742443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = ensemble.predict_proba(test_data)\n",
        "print('Test scores: {}'.format(roc_auc_score(test_labels['toxic'].values, test_preds[:, 0])))"
      ],
      "metadata": {
        "id": "-8g-k9rFi_GR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0cf30f-2ebe-4ad5-fae3-7d23d7afad74"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test scores: 0.8843136524336524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итого:**\n",
        "- *Validation scores*: 0.9087164536742443\n",
        "- *Test scores*: 0.8843136524336524"
      ],
      "metadata": {
        "id": "IG00dj3Rjl0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Выводы**\n",
        "Получилось обогнать LightAutoML за счет ансамблирования двух трансформеров, но такой подход оказался гораздо более требовательным к ресурсам, из-за чего пришлось обучать на предобработанном датасете меньшего размера и с небольшим числом подбираемых с помощью optuna гиперпараметров. LightAutoML действительно хорош для быстрого и относительно простого достижения хороших результатов!\n",
        "\n",
        "Лучший скор на тестовой выборке **0.88**."
      ],
      "metadata": {
        "id": "b036GFCkj2CK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2AXhtB0iZcE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}